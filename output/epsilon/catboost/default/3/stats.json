{
    "config": {
        "data": {
            "path": "data/epsilon"
        },
        "fit": {
            "logging_level": "Verbose"
        },
        "model": {
            "iterations": 2000,
            "task_type": "CPU",
            "thread_count": 10
        },
        "seed": 3
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "dataset": "epsilon",
    "algorithm": "catboost_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9244884570928743,
                "recall": 0.92398621223664,
                "f1-score": 0.9242372664328522,
                "support": 160142
            },
            "1": {
                "precision": 0.9238925880771515,
                "recall": 0.924395400918315,
                "f1-score": 0.924143926104508,
                "support": 159858
            },
            "accuracy": 0.924190625,
            "macro avg": {
                "precision": 0.9241905225850129,
                "recall": 0.9241908065774775,
                "f1-score": 0.92419059626868,
                "support": 320000
            },
            "weighted avg": {
                "precision": 0.9241907870018886,
                "recall": 0.924190625,
                "f1-score": 0.9241906376884508,
                "support": 320000
            },
            "roc_auc": 0.9781701905790516,
            "score": 0.924190625
        },
        "val": {
            "0": {
                "precision": 0.8886059516676653,
                "recall": 0.8890720619457975,
                "f1-score": 0.8888389456992671,
                "support": 40035
            },
            "1": {
                "precision": 0.8888193470859203,
                "recall": 0.888352308269736,
                "f1-score": 0.8885857663091767,
                "support": 39965
            },
            "accuracy": 0.8887125,
            "macro avg": {
                "precision": 0.8887126493767927,
                "recall": 0.8887121851077667,
                "f1-score": 0.8887123560042219,
                "support": 80000
            },
            "weighted avg": {
                "precision": 0.8887125560162973,
                "recall": 0.8887125,
                "f1-score": 0.8887124667702052,
                "support": 80000
            },
            "roc_auc": 0.9563390865721131,
            "score": 0.8887125
        },
        "test": {
            "0": {
                "precision": 0.8860422095359338,
                "recall": 0.8900789289639325,
                "f1-score": 0.8880559819773122,
                "support": 50045
            },
            "1": {
                "precision": 0.8893759929213506,
                "recall": 0.885316785106596,
                "f1-score": 0.8873417467546799,
                "support": 49955
            },
            "accuracy": 0.8877,
            "macro avg": {
                "precision": 0.8877091012286422,
                "recall": 0.8876978570352643,
                "f1-score": 0.887698864365996,
                "support": 100000
            },
            "weighted avg": {
                "precision": 0.8877076010261188,
                "recall": 0.8877,
                "f1-score": 0.8876991857718463,
                "support": 100000
            },
            "roc_auc": 0.9562299705462761,
            "score": 0.8877
        }
    }
}
