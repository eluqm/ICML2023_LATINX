{
    "config": {
        "data": {
            "path": "data/epsilon"
        },
        "fit": {
            "logging_level": "Verbose"
        },
        "model": {
            "iterations": 2000,
            "task_type": "CPU",
            "thread_count": 10
        },
        "seed": 12
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "dataset": "epsilon",
    "algorithm": "catboost_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9270552223888056,
                "recall": 0.926696307027513,
                "f1-score": 0.9268757299623386,
                "support": 160142
            },
            "1": {
                "precision": 0.9265945472736368,
                "recall": 0.9269539216054248,
                "f1-score": 0.9267741996009732,
                "support": 159858
            },
            "accuracy": 0.926825,
            "macro avg": {
                "precision": 0.9268248848312212,
                "recall": 0.926825114316469,
                "f1-score": 0.9268249647816559,
                "support": 320000
            },
            "weighted avg": {
                "precision": 0.9268250892558035,
                "recall": 0.926825,
                "f1-score": 0.9268250098357538,
                "support": 320000
            },
            "roc_auc": 0.9794978668201169,
            "score": 0.926825
        },
        "val": {
            "0": {
                "precision": 0.8895438876954589,
                "recall": 0.8895216685400275,
                "f1-score": 0.8895327779789932,
                "support": 40035
            },
            "1": {
                "precision": 0.8893309312915979,
                "recall": 0.8893531840360315,
                "f1-score": 0.8893420575246149,
                "support": 39965
            },
            "accuracy": 0.8894375,
            "macro avg": {
                "precision": 0.8894374094935285,
                "recall": 0.8894374262880295,
                "f1-score": 0.8894374177518041,
                "support": 80000
            },
            "weighted avg": {
                "precision": 0.889437502661955,
                "recall": 0.8894375,
                "f1-score": 0.8894375011920028,
                "support": 80000
            },
            "roc_auc": 0.9565201760857597,
            "score": 0.8894375
        },
        "test": {
            "0": {
                "precision": 0.8860759493670886,
                "recall": 0.8895993605754821,
                "f1-score": 0.8878341592796817,
                "support": 50045
            },
            "1": {
                "precision": 0.8889581156041483,
                "recall": 0.8854168751876689,
                "f1-score": 0.887183961649166,
                "support": 49955
            },
            "accuracy": 0.88751,
            "macro avg": {
                "precision": 0.8875170324856184,
                "recall": 0.8875081178815755,
                "f1-score": 0.8875090604644238,
                "support": 100000
            },
            "weighted avg": {
                "precision": 0.8875157355108118,
                "recall": 0.88751,
                "f1-score": 0.8875093530533577,
                "support": 100000
            },
            "roc_auc": 0.9561673424955474,
            "score": 0.88751
        }
    }
}
