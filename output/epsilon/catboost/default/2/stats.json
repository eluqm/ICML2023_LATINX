{
    "config": {
        "data": {
            "path": "data/epsilon"
        },
        "fit": {
            "logging_level": "Verbose"
        },
        "model": {
            "iterations": 2000,
            "task_type": "CPU",
            "thread_count": 10
        },
        "seed": 2
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "dataset": "epsilon",
    "algorithm": "catboost_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9253243506736994,
                "recall": 0.9245731912927277,
                "f1-score": 0.9249486184773579,
                "support": 160142
            },
            "1": {
                "precision": 0.9245005875440658,
                "recall": 0.9252524115152198,
                "f1-score": 0.9248763467418695,
                "support": 159858
            },
            "accuracy": 0.9249125,
            "macro avg": {
                "precision": 0.9249124691088826,
                "recall": 0.9249128014039738,
                "f1-score": 0.9249124826096137,
                "support": 320000
            },
            "weighted avg": {
                "precision": 0.9249128346537713,
                "recall": 0.9249125,
                "f1-score": 0.9249125146801964,
                "support": 320000
            },
            "roc_auc": 0.9786462841962373,
            "score": 0.9249125
        },
        "val": {
            "0": {
                "precision": 0.8894361795224403,
                "recall": 0.8885475209191958,
                "f1-score": 0.8889916281394477,
                "support": 40035
            },
            "1": {
                "precision": 0.8884639420072491,
                "recall": 0.8893531840360315,
                "f1-score": 0.8889083406277355,
                "support": 39965
            },
            "accuracy": 0.88895,
            "macro avg": {
                "precision": 0.8889500607648446,
                "recall": 0.8889503524776137,
                "f1-score": 0.8889499843835915,
                "support": 80000
            },
            "weighted avg": {
                "precision": 0.8889504861187576,
                "recall": 0.88895,
                "f1-score": 0.8889500208218778,
                "support": 80000
            },
            "roc_auc": 0.9564701772974795,
            "score": 0.88895
        },
        "test": {
            "0": {
                "precision": 0.8873247849633641,
                "recall": 0.8904985513038266,
                "f1-score": 0.8889088352332226,
                "support": 50045
            },
            "1": {
                "precision": 0.8899067823850851,
                "recall": 0.8867180462416174,
                "f1-score": 0.8883095526967543,
                "support": 49955
            },
            "accuracy": 0.88861,
            "macro avg": {
                "precision": 0.8886157836742246,
                "recall": 0.888608298772722,
                "f1-score": 0.8886091939649885,
                "support": 100000
            },
            "weighted avg": {
                "precision": 0.8886146217753849,
                "recall": 0.88861,
                "f1-score": 0.8886094636421299,
                "support": 100000
            },
            "roc_auc": 0.9563726706618633,
            "score": 0.88861
        }
    }
}
