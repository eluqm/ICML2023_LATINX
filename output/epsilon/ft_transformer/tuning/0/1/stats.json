{
    "dataset": "epsilon",
    "algorithm": "ft_transformer",
    "config": {
        "data": {
            "path": "data/epsilon"
        },
        "model": {
            "activation": "reglu",
            "attention_dropout": 0.15,
            "d_ffn_factor": 1.333333333333333,
            "d_token": 128,
            "ffn_dropout": 0.05,
            "initialization": "kaiming",
            "kv_compression": 0.064,
            "kv_compression_sharing": "headwise",
            "n_heads": 8,
            "n_layers": 2,
            "prenormalization": true,
            "residual_dropout": 0.0
        },
        "seed": 0,
        "training": {
            "batch_size": 1024,
            "eval_batch_size": 8192,
            "lr": 0.0001,
            "lr_n_decays": 0,
            "n_epochs": 1000000000,
            "optimizer": "adamw",
            "patience": 16,
            "weight_decay": 1e-05
        }
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0,1,2,3",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            },
            "1": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            },
            "2": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            },
            "3": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "epoch_size": 313,
    "n_parameters": 1801385,
    "eval_batch_size": 4096,
    "best_epoch": 27,
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9077602942679064,
                "recall": 0.8876372219655057,
                "f1-score": 0.8975859869796107,
                "support": 160142
            },
            "1": {
                "precision": 0.8898829922647606,
                "recall": 0.9096448097686697,
                "f1-score": 0.8996553921538301,
                "support": 159858
            },
            "accuracy": 0.89863125,
            "macro avg": {
                "precision": 0.8988216432663335,
                "recall": 0.8986410158670877,
                "f1-score": 0.8986206895667204,
                "support": 320000
            },
            "weighted avg": {
                "precision": 0.8988295763190974,
                "recall": 0.89863125,
                "f1-score": 0.8986197712681744,
                "support": 320000
            },
            "roc_auc": 0.9637308119987537,
            "score": 0.89863125
        },
        "val": {
            "0": {
                "precision": 0.9056748466257669,
                "recall": 0.8849756463094792,
                "f1-score": 0.8952056092476787,
                "support": 40035
            },
            "1": {
                "precision": 0.887353228962818,
                "recall": 0.9076692105592393,
                "f1-score": 0.8973962520873277,
                "support": 39965
            },
            "accuracy": 0.8963125,
            "macro avg": {
                "precision": 0.8965140377942924,
                "recall": 0.8963224284343593,
                "f1-score": 0.8963009306675032,
                "support": 80000
            },
            "weighted avg": {
                "precision": 0.8965220535020199,
                "recall": 0.8963125,
                "f1-score": 0.8962999722612607,
                "support": 80000
            },
            "roc_auc": 0.9624636987612694,
            "score": 0.8963125
        },
        "test": {
            "0": {
                "precision": 0.9041583594417545,
                "recall": 0.8880607453292038,
                "f1-score": 0.8960372584401052,
                "support": 50045
            },
            "1": {
                "precision": 0.8898241749596821,
                "recall": 0.9056951256130518,
                "f1-score": 0.8976895070485411,
                "support": 49955
            },
            "accuracy": 0.89687,
            "macro avg": {
                "precision": 0.8969912672007183,
                "recall": 0.8968779354711278,
                "f1-score": 0.8968633827443231,
                "support": 100000
            },
            "weighted avg": {
                "precision": 0.8969977175837354,
                "recall": 0.89687,
                "f1-score": 0.8968626392324492,
                "support": 100000
            },
            "roc_auc": 0.9624368619738581,
            "score": 0.89687
        }
    },
    "time": "1:08:49"
}
