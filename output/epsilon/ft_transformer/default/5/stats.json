{
    "dataset": "epsilon",
    "algorithm": "ft_transformer",
    "config": {
        "data": {
            "path": "data/epsilon"
        },
        "model": {
            "activation": "reglu",
            "attention_dropout": 0.2,
            "d_ffn_factor": 1.333333333333333,
            "d_token": 192,
            "ffn_dropout": 0.1,
            "initialization": "kaiming",
            "kv_compression": 0.064,
            "kv_compression_sharing": "headwise",
            "n_heads": 8,
            "n_layers": 3,
            "prenormalization": true,
            "residual_dropout": 0.0
        },
        "seed": 5,
        "training": {
            "batch_size": 1024,
            "eval_batch_size": 8192,
            "lr": 0.0001,
            "lr_n_decays": 0,
            "n_epochs": 1000000000,
            "optimizer": "adamw",
            "patience": 16,
            "weight_decay": 1e-05
        }
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0,1,2,3",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            },
            "1": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            },
            "2": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            },
            "3": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "epoch_size": 313,
    "n_parameters": 3194875,
    "eval_batch_size": 2048,
    "best_epoch": 17,
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8961848521839351,
                "recall": 0.9031297223713954,
                "f1-score": 0.899643884612394,
                "support": 160142
            },
            "1": {
                "precision": 0.9021983772231223,
                "recall": 0.8951944851055311,
                "f1-score": 0.8986827851479707,
                "support": 159858
            },
            "accuracy": 0.899165625,
            "macro avg": {
                "precision": 0.8991916147035287,
                "recall": 0.8991621037384633,
                "f1-score": 0.8991633348801824,
                "support": 320000
            },
            "weighted avg": {
                "precision": 0.8991889462017926,
                "recall": 0.899165625,
                "f1-score": 0.8991637613680697,
                "support": 320000
            },
            "roc_auc": 0.9640213658213602,
            "score": 0.899165625
        },
        "val": {
            "0": {
                "precision": 0.8918798334324807,
                "recall": 0.8987635818658674,
                "f1-score": 0.8953084760945024,
                "support": 40035
            },
            "1": {
                "precision": 0.8977960459955618,
                "recall": 0.8908544976854748,
                "f1-score": 0.8943118021627459,
                "support": 39965
            },
            "accuracy": 0.8948125,
            "macro avg": {
                "precision": 0.8948379397140213,
                "recall": 0.8948090397756711,
                "f1-score": 0.8948101391286241,
                "support": 80000
            },
            "weighted avg": {
                "precision": 0.8948353513710248,
                "recall": 0.8948125,
                "f1-score": 0.8948105751734693,
                "support": 80000
            },
            "roc_auc": 0.9614197151494693,
            "score": 0.8948125
        },
        "test": {
            "0": {
                "precision": 0.8905285170352542,
                "recall": 0.9019882106104506,
                "f1-score": 0.8962217324835705,
                "support": 50045
            },
            "1": {
                "precision": 0.9005292936667275,
                "recall": 0.8889200280252227,
                "f1-score": 0.8946870025990773,
                "support": 49955
            },
            "accuracy": 0.89546,
            "macro avg": {
                "precision": 0.8955289053509908,
                "recall": 0.8954541193178367,
                "f1-score": 0.8954543675413239,
                "support": 100000
            },
            "weighted avg": {
                "precision": 0.8955244050015067,
                "recall": 0.89546,
                "f1-score": 0.895455058169772,
                "support": 100000
            },
            "roc_auc": 0.9611941243672407,
            "score": 0.89546
        }
    },
    "time": "2:11:13"
}
