seed = 12

[data]
normalization = 'quantile'
path = 'data/yahoo'
y_policy = 'mean_std'

[model]
batch_momentum = 0.95
feature_dim = 128
num_decision_steps = 5
relaxation_factor = 1.083170448154951
virtual_batch_size = 512

[training]
batch_size = 16384
display_steps = 100
epochs = 50000
grad_thresh = 2000.0
patience = 16
sparsity_loss_weight = 0.0002764667901385369

    [training.schedule]
    decay_rate = 0.8490266903579612
    decay_steps = 2000
    learning_rate = 0.009853253861293192
