{
    "config": {
        "base_config": {
            "data": {
                "normalization": "quantile",
                "path": "data/year",
                "y_policy": "mean_std"
            },
            "model": {
                "activation": "reglu",
                "d_ffn_factor": 1.333333333333333,
                "initialization": "kaiming",
                "n_heads": 8,
                "prenormalization": true,
                "residual_dropout": 0.0,
                "token_bias": false,
                "token_cat_bias": false
            },
            "seed": 0,
            "training": {
                "batch_size": 1024,
                "eval_batch_size": 8192,
                "n_epochs": 1000000000,
                "optimizer": "adamw",
                "patience": 16
            }
        },
        "optimization": {
            "options": {
                "n_trials": 50
            },
            "sampler": {
                "seed": 0
            },
            "space": {
                "model": {
                    "attention_dropout": [
                        "uniform",
                        0.0,
                        0.5
                    ],
                    "d_token": [
                        "$d_token",
                        64,
                        512
                    ],
                    "ffn_dropout": [
                        "uniform",
                        0.0,
                        0.5
                    ],
                    "n_layers": [
                        "int",
                        1,
                        6
                    ]
                },
                "training": {
                    "lr": [
                        "loguniform",
                        3e-05,
                        0.0003
                    ],
                    "weight_decay": [
                        "loguniform",
                        1e-06,
                        0.001
                    ]
                }
            }
        },
        "program": "bin/ft_transformer.py"
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0,1",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            },
            "1": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "best_stats": {
        "dataset": "year",
        "algorithm": "ft_transformer",
        "config": {
            "data": {
                "normalization": "quantile",
                "path": "data/year",
                "y_policy": "mean_std"
            },
            "model": {
                "activation": "reglu",
                "attention_dropout": 0.1717571032133184,
                "d_ffn_factor": 1.333333333333333,
                "d_token": 272,
                "ffn_dropout": 0.2663731938040036,
                "initialization": "kaiming",
                "n_heads": 8,
                "n_layers": 1,
                "prenormalization": true,
                "residual_dropout": 0.0,
                "token_bias": false,
                "token_cat_bias": false
            },
            "seed": 0,
            "training": {
                "batch_size": 1024,
                "eval_batch_size": 8192,
                "lr": 4.387551348229791e-05,
                "n_epochs": 1000000000,
                "optimizer": "adamw",
                "patience": 16,
                "weight_decay": 0.0001167682692325073
            }
        },
        "environment": {
            "devices": {
                "CUDA_VISIBLE_DEVICES": "0,1",
                "torch.version.cuda": "10.1",
                "torch.backends.cudnn.version()": 7603,
                "torch.cuda.nccl.version()": 2708,
                "driver": "450.80.02",
                "0": {
                    "name": "Tesla V100-PCIE-32GB",
                    "total_memory": 34089730048
                },
                "1": {
                    "name": "Tesla V100-PCIE-32GB",
                    "total_memory": 34089730048
                }
            }
        },
        "epoch_size": 363,
        "n_parameters": 619525,
        "best_epoch": 127,
        "metrics": {
            "train": {
                "rmse": 7.90980842906464,
                "score": -7.90980842906464
            },
            "val": {
                "rmse": 8.508625553300645,
                "score": -8.508625553300645
            },
            "test": {
                "rmse": 8.83886955444948,
                "score": -8.83886955444948
            }
        },
        "time": "0:32:02",
        "trial_id": 34,
        "tuning_time": "19:48:03"
    },
    "time": "1 day, 3:06:12"
}
