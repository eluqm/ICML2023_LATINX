{
    "config": {
        "base_config": {
            "data": {
                "normalization": "quantile",
                "path": "data/year",
                "y_policy": "mean_std"
            },
            "model": {
                "activation": "reglu",
                "d_ffn_factor": 1.333333333333333,
                "initialization": "kaiming",
                "n_heads": 8,
                "prenormalization": true,
                "residual_dropout": 0.0
            },
            "seed": 0,
            "training": {
                "batch_size": 1024,
                "eval_batch_size": 8192,
                "n_epochs": 1000000000,
                "optimizer": "adamw",
                "patience": 16
            }
        },
        "optimization": {
            "options": {
                "n_trials": 50
            },
            "sampler": {
                "seed": 0
            },
            "space": {
                "model": {
                    "attention_dropout": [
                        "uniform",
                        0.0,
                        0.5
                    ],
                    "d_token": [
                        "$d_token",
                        64,
                        512
                    ],
                    "ffn_dropout": [
                        "uniform",
                        0.0,
                        0.5
                    ],
                    "n_layers": [
                        "int",
                        1,
                        6
                    ]
                },
                "training": {
                    "lr": [
                        "loguniform",
                        3e-05,
                        0.0003
                    ],
                    "weight_decay": [
                        "loguniform",
                        1e-06,
                        0.001
                    ]
                }
            }
        },
        "program": "bin/ft_transformer.py"
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0,1",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            },
            "1": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "continuations": [
        3,
        47
    ],
    "best_stats": {
        "dataset": "year",
        "algorithm": "ft_transformer",
        "config": {
            "data": {
                "normalization": "quantile",
                "path": "data/year",
                "y_policy": "mean_std"
            },
            "model": {
                "activation": "reglu",
                "attention_dropout": 0.3950042559826507,
                "d_ffn_factor": 1.333333333333333,
                "d_token": 384,
                "ffn_dropout": 0.294021729767271,
                "initialization": "kaiming",
                "n_heads": 8,
                "n_layers": 1,
                "prenormalization": true,
                "residual_dropout": 0.0
            },
            "seed": 0,
            "training": {
                "batch_size": 1024,
                "eval_batch_size": 8192,
                "lr": 6.892111668257778e-05,
                "n_epochs": 1000000000,
                "optimizer": "adamw",
                "patience": 16,
                "weight_decay": 5.05413243507343e-05
            }
        },
        "environment": {
            "devices": {
                "CUDA_VISIBLE_DEVICES": "0,1",
                "torch.version.cuda": "10.1",
                "torch.backends.cudnn.version()": 7603,
                "torch.cuda.nccl.version()": 2708,
                "driver": "450.80.02",
                "0": {
                    "name": "Tesla V100-PCIE-32GB",
                    "total_memory": 34089730048
                },
                "1": {
                    "name": "Tesla V100-PCIE-32GB",
                    "total_memory": 34089730048
                }
            }
        },
        "epoch_size": 363,
        "n_parameters": 1252863,
        "best_epoch": 165,
        "metrics": {
            "train": {
                "rmse": 7.526005413533924,
                "score": -7.526005413533924
            },
            "val": {
                "rmse": 8.466199842946269,
                "score": -8.466199842946269
            },
            "test": {
                "rmse": 8.903925139266454,
                "score": -8.903925139266454
            }
        },
        "time": "0:23:43",
        "trial_id": 13,
        "tuning_time": "9:03:17"
    },
    "time": "1 day, 2:29:23"
}
