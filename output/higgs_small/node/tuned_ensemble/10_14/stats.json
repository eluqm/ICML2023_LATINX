{
    "dataset": "higgs_small",
    "algorithm": "node",
    "config": {
        "source": "output/higgs_small/node/tuned_2",
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ],
        "count": 5
    },
    "metrics": {
        "val": {
            "0": {
                "precision": 0.7168633835300502,
                "recall": 0.7144402379664684,
                "f1-score": 0.7156497595991061,
                "support": 7396
            },
            "1": {
                "precision": 0.7460622820728628,
                "recall": 0.7483116256632899,
                "f1-score": 0.7471852610030706,
                "support": 8292
            },
            "accuracy": 0.7323431922488526,
            "macro avg": {
                "precision": 0.7314628328014565,
                "recall": 0.7313759318148791,
                "f1-score": 0.7314175103010884,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.7322966616226689,
                "recall": 0.7323431922488526,
                "f1-score": 0.7323180651601511,
                "support": 15688
            },
            "roc_auc": 0.8137360659873513,
            "pr_auc": 0.8277546033468383,
            "score": 0.7323431922488526
        },
        "test": {
            "0": {
                "precision": 0.7095212479827865,
                "recall": 0.7133585722011898,
                "f1-score": 0.7114347357065803,
                "support": 9245
            },
            "1": {
                "precision": 0.7430925836160931,
                "recall": 0.7395079594790159,
                "f1-score": 0.7412959381044487,
                "support": 10365
            },
            "accuracy": 0.7271800101988781,
            "macro avg": {
                "precision": 0.7263069157994397,
                "recall": 0.7264332658401029,
                "f1-score": 0.7263653369055145,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7272656076890192,
                "recall": 0.7271800101988781,
                "f1-score": 0.7272180790443624,
                "support": 19610
            },
            "roc_auc": 0.8057084193304578,
            "pr_auc": 0.8209004740117436,
            "score": 0.7271800101988781
        }
    }
}
