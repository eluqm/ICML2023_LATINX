{
    "dataset": "higgs_small",
    "algorithm": "resnet",
    "config": {
        "data": {
            "normalization": "quantile",
            "path": "data/higgs_small"
        },
        "model": {
            "activation": "relu",
            "d": 266,
            "d_hidden_factor": 1.330457169042573,
            "hidden_dropout": 0.3473780108857106,
            "n_layers": 3,
            "normalization": "batchnorm",
            "residual_dropout": 0.1478460640899281
        },
        "seed": 6,
        "training": {
            "batch_size": 512,
            "eval_batch_size": 8192,
            "lr": 0.001377976313474588,
            "n_epochs": 1000000000,
            "optimizer": "adamw",
            "patience": 16,
            "weight_decay": 0.0
        }
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "epoch_size": 123,
    "n_parameters": 575354,
    "best_epoch": 32,
    "metrics": {
        "train": {
            "0": {
                "precision": 0.7630913052646376,
                "recall": 0.7339936447839903,
                "f1-score": 0.7482597008753189,
                "support": 29582
            },
            "1": {
                "precision": 0.7705697125196804,
                "recall": 0.7967741935483871,
                "f1-score": 0.7834528961878224,
                "support": 33170
            },
            "accuracy": 0.7671787353391127,
            "macro avg": {
                "precision": 0.766830508892159,
                "recall": 0.7653839191661886,
                "f1-score": 0.7658562985315707,
                "support": 62752
            },
            "weighted avg": {
                "precision": 0.7670443070597959,
                "recall": 0.7671787353391127,
                "f1-score": 0.766862427298632,
                "support": 62752
            },
            "roc_auc": 0.8535532560632217,
            "pr_auc": 0.868550536023391,
            "score": 0.7671787353391127
        },
        "val": {
            "0": {
                "precision": 0.7315114804902099,
                "recall": 0.7021362898864251,
                "f1-score": 0.7165229389444635,
                "support": 7396
            },
            "1": {
                "precision": 0.7435091395971591,
                "recall": 0.7701398938736131,
                "f1-score": 0.7565902493928084,
                "support": 8292
            },
            "accuracy": 0.7380800611932687,
            "macro avg": {
                "precision": 0.7375103100436845,
                "recall": 0.7361380918800191,
                "f1-score": 0.736556594168636,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.7378529255000789,
                "recall": 0.7380800611932687,
                "f1-score": 0.737700790693423,
                "support": 15688
            },
            "roc_auc": 0.8158126829354834,
            "pr_auc": 0.82860006973443,
            "score": 0.7380800611932687
        },
        "test": {
            "0": {
                "precision": 0.7193635748138117,
                "recall": 0.6895619253650622,
                "f1-score": 0.7041475672391893,
                "support": 9245
            },
            "1": {
                "precision": 0.732973576479345,
                "recall": 0.7600578871201158,
                "f1-score": 0.746270070572633,
                "support": 10365
            },
            "accuracy": 0.7268230494645589,
            "macro avg": {
                "precision": 0.7261685756465783,
                "recall": 0.724809906242589,
                "f1-score": 0.7252088189059112,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7265572345416675,
                "recall": 0.7268230494645589,
                "f1-score": 0.7264117052836127,
                "support": 19610
            },
            "roc_auc": 0.8078948503995718,
            "pr_auc": 0.8214479290044265,
            "score": 0.7268230494645589
        }
    },
    "time": "0:01:19"
}
