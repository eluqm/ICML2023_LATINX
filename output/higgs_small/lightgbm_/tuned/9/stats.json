{
    "config": {
        "data": {
            "path": "data/higgs_small",
            "y_policy": "mean_std"
        },
        "fit": {
            "early_stopping_rounds": 50,
            "verbose": true
        },
        "model": {
            "colsample_bytree": 0.7999440674588046,
            "learning_rate": 0.04183849804413404,
            "min_child_samples": 81,
            "min_child_weight": 0.00676057460469568,
            "n_estimators": 2000,
            "n_jobs": 1,
            "num_leaves": 94,
            "reg_lambda": 0.006637134146517112,
            "subsample": 0.6165566522563218
        },
        "seed": 9
    },
    "environment": {},
    "dataset": "higgs_small",
    "algorithm": "lightgbm_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8035433340173747,
                "recall": 0.7941991751740923,
                "f1-score": 0.7988439306358381,
                "support": 29582
            },
            "1": {
                "precision": 0.8183445724174971,
                "recall": 0.8268314742236961,
                "f1-score": 0.8225661328054705,
                "support": 33170
            },
            "accuracy": 0.8114482406935237,
            "macro avg": {
                "precision": 0.8109439532174358,
                "recall": 0.8105153246988942,
                "f1-score": 0.8107050317206543,
                "support": 62752
            },
            "weighted avg": {
                "precision": 0.8113671018292701,
                "recall": 0.8114482406935237,
                "f1-score": 0.811383219359173,
                "support": 62752
            },
            "roc_auc": 0.8948473227013298,
            "score": 0.8114482406935237
        },
        "val": {
            "0": {
                "precision": 0.7125732189075058,
                "recall": 0.7072742022714981,
                "f1-score": 0.7099138223519033,
                "support": 7396
            },
            "1": {
                "precision": 0.740625374386007,
                "recall": 0.7455378678244091,
                "f1-score": 0.7430735020133422,
                "support": 8292
            },
            "accuracy": 0.7274987251402346,
            "macro avg": {
                "precision": 0.7265992966467564,
                "recall": 0.7264060350479535,
                "f1-score": 0.7264936621826228,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.7274003780882637,
                "recall": 0.7274987251402346,
                "f1-score": 0.7274405984707617,
                "support": 15688
            },
            "roc_auc": 0.8090202308805923,
            "score": 0.7274987251402346
        },
        "test": {
            "0": {
                "precision": 0.7119613016710642,
                "recall": 0.7004867495943753,
                "f1-score": 0.7061774167166458,
                "support": 9245
            },
            "1": {
                "precision": 0.7366368651322047,
                "recall": 0.7472262421611191,
                "f1-score": 0.7418937688586618,
                "support": 10365
            },
            "accuracy": 0.7251912289648139,
            "macro avg": {
                "precision": 0.7242990834016345,
                "recall": 0.7238564958777471,
                "f1-score": 0.7240355927876538,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7250037399818609,
                "recall": 0.7251912289648139,
                "f1-score": 0.7250555396106793,
                "support": 19610
            },
            "roc_auc": 0.8038364853219835,
            "score": 0.7251912289648139
        }
    },
    "time": "0:00:06"
}
