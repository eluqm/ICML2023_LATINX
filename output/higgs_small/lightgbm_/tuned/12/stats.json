{
    "config": {
        "data": {
            "path": "data/higgs_small",
            "y_policy": "mean_std"
        },
        "fit": {
            "early_stopping_rounds": 50,
            "verbose": true
        },
        "model": {
            "colsample_bytree": 0.7999440674588046,
            "learning_rate": 0.04183849804413404,
            "min_child_samples": 81,
            "min_child_weight": 0.00676057460469568,
            "n_estimators": 2000,
            "n_jobs": 1,
            "num_leaves": 94,
            "reg_lambda": 0.006637134146517112,
            "subsample": 0.6165566522563218
        },
        "seed": 12
    },
    "environment": {},
    "dataset": "higgs_small",
    "algorithm": "lightgbm_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.7667255314813557,
                "recall": 0.7632005949563924,
                "f1-score": 0.7649590025072847,
                "support": 29582
            },
            "1": {
                "precision": 0.789677535579175,
                "recall": 0.7929152848959904,
                "f1-score": 0.7912930982610267,
                "support": 33170
            },
            "accuracy": 0.7789074451810301,
            "macro avg": {
                "precision": 0.7782015335302653,
                "recall": 0.7780579399261913,
                "f1-score": 0.7781260503841556,
                "support": 62752
            },
            "weighted avg": {
                "precision": 0.7788577021838776,
                "recall": 0.7789074451810301,
                "f1-score": 0.7788789087437652,
                "support": 62752
            },
            "roc_auc": 0.8641486859405965,
            "score": 0.7789074451810301
        },
        "val": {
            "0": {
                "precision": 0.711799891245242,
                "recall": 0.7079502433747972,
                "f1-score": 0.7098698481561823,
                "support": 7396
            },
            "1": {
                "precision": 0.7407585213634181,
                "recall": 0.7443318861553304,
                "f1-score": 0.7425409047160731,
                "support": 8292
            },
            "accuracy": 0.7271800101988781,
            "macro avg": {
                "precision": 0.7262792063043301,
                "recall": 0.7261410647650638,
                "f1-score": 0.7262053764361277,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.727106173814079,
                "recall": 0.7271800101988781,
                "f1-score": 0.7271383591833759,
                "support": 15688
            },
            "roc_auc": 0.8068469038556714,
            "score": 0.7271800101988781
        },
        "test": {
            "0": {
                "precision": 0.70640802092415,
                "recall": 0.7011357490535425,
                "f1-score": 0.7037620107486022,
                "support": 9245
            },
            "1": {
                "precision": 0.7351926394479587,
                "recall": 0.7400868306801737,
                "f1-score": 0.7376316169046588,
                "support": 10365
            },
            "accuracy": 0.7217236104028557,
            "macro avg": {
                "precision": 0.7208003301860544,
                "recall": 0.7206112898668581,
                "f1-score": 0.7206968138266305,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7216223284712829,
                "recall": 0.7217236104028557,
                "f1-score": 0.721664023385396,
                "support": 19610
            },
            "roc_auc": 0.8009708172003119,
            "score": 0.7217236104028557
        }
    },
    "time": "0:00:04"
}
