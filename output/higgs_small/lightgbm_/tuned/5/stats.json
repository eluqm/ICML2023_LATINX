{
    "config": {
        "data": {
            "path": "data/higgs_small",
            "y_policy": "mean_std"
        },
        "fit": {
            "early_stopping_rounds": 50,
            "verbose": true
        },
        "model": {
            "colsample_bytree": 0.7999440674588046,
            "learning_rate": 0.04183849804413404,
            "min_child_samples": 81,
            "min_child_weight": 0.00676057460469568,
            "n_estimators": 2000,
            "n_jobs": 1,
            "num_leaves": 94,
            "reg_lambda": 0.006637134146517112,
            "subsample": 0.6165566522563218
        },
        "seed": 5
    },
    "environment": {},
    "dataset": "higgs_small",
    "algorithm": "lightgbm_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.7974956378938726,
                "recall": 0.7879791765262659,
                "f1-score": 0.7927088469844077,
                "support": 29582
            },
            "1": {
                "precision": 0.8129045729797453,
                "recall": 0.8215556225504974,
                "f1-score": 0.8172072031547539,
                "support": 33170
            },
            "accuracy": 0.8057273074961754,
            "macro avg": {
                "precision": 0.805200105436809,
                "recall": 0.8047673995383817,
                "f1-score": 0.8049580250695808,
                "support": 62752
            },
            "weighted avg": {
                "precision": 0.8056406273252595,
                "recall": 0.8057273074961754,
                "f1-score": 0.8056584019654502,
                "support": 62752
            },
            "roc_auc": 0.889812081090386,
            "score": 0.8057273074961754
        },
        "val": {
            "0": {
                "precision": 0.7126515048345363,
                "recall": 0.7075446187128177,
                "f1-score": 0.7100888798425945,
                "support": 7396
            },
            "1": {
                "precision": 0.7408028759736369,
                "recall": 0.7455378678244091,
                "f1-score": 0.7431628298371101,
                "support": 8292
            },
            "accuracy": 0.7276262111167772,
            "macro avg": {
                "precision": 0.7267271904040866,
                "recall": 0.7265412432686134,
                "f1-score": 0.7266258548398523,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.7275311051331991,
                "recall": 0.7276262111167772,
                "f1-score": 0.7275703429580026,
                "support": 15688
            },
            "roc_auc": 0.8092276740768338,
            "score": 0.7276262111167772
        },
        "test": {
            "0": {
                "precision": 0.7120980091883614,
                "recall": 0.7041644131963224,
                "f1-score": 0.7081089900473161,
                "support": 9245
            },
            "1": {
                "precision": 0.7387275506304929,
                "recall": 0.7460684997588036,
                "f1-score": 0.7423798780780492,
                "support": 10365
            },
            "accuracy": 0.7263131055583886,
            "macro avg": {
                "precision": 0.7254127799094272,
                "recall": 0.725116456477563,
                "f1-score": 0.7252444340626827,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7261732359628486,
                "recall": 0.7263131055583886,
                "f1-score": 0.7262231029712604,
                "support": 19610
            },
            "roc_auc": 0.8039428465132977,
            "score": 0.7263131055583886
        }
    },
    "time": "0:00:06"
}
