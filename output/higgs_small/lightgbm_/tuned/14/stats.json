{
    "config": {
        "data": {
            "path": "data/higgs_small",
            "y_policy": "mean_std"
        },
        "fit": {
            "early_stopping_rounds": 50,
            "verbose": true
        },
        "model": {
            "colsample_bytree": 0.7999440674588046,
            "learning_rate": 0.04183849804413404,
            "min_child_samples": 81,
            "min_child_weight": 0.00676057460469568,
            "n_estimators": 2000,
            "n_jobs": 1,
            "num_leaves": 94,
            "reg_lambda": 0.006637134146517112,
            "subsample": 0.6165566522563218
        },
        "seed": 14
    },
    "environment": {},
    "dataset": "higgs_small",
    "algorithm": "lightgbm_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8062949024974342,
                "recall": 0.7967006963694139,
                "f1-score": 0.8014690879412365,
                "support": 29582
            },
            "1": {
                "precision": 0.820595429866953,
                "recall": 0.8293035875791378,
                "f1-score": 0.8249265279193906,
                "support": 33170
            },
            "accuracy": 0.813934217236104,
            "macro avg": {
                "precision": 0.8134451661821935,
                "recall": 0.8130021419742759,
                "f1-score": 0.8131978079303135,
                "support": 62752
            },
            "weighted avg": {
                "precision": 0.8138540001014458,
                "recall": 0.813934217236104,
                "f1-score": 0.8138684263539623,
                "support": 62752
            },
            "roc_auc": 0.897689685815713,
            "score": 0.813934217236104
        },
        "val": {
            "0": {
                "precision": 0.7127760466061509,
                "recall": 0.7113304488912926,
                "f1-score": 0.7120525140420924,
                "support": 7396
            },
            "1": {
                "precision": 0.7429878415793909,
                "recall": 0.7443318861553304,
                "f1-score": 0.7436592565817219,
                "support": 8292
            },
            "accuracy": 0.7287735849056604,
            "macro avg": {
                "precision": 0.7278819440927708,
                "recall": 0.7278311675233116,
                "f1-score": 0.7278558853119071,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.7287446980542709,
                "recall": 0.7287735849056604,
                "f1-score": 0.7287584745940179,
                "support": 15688
            },
            "roc_auc": 0.8095672599913852,
            "score": 0.7287735849056604
        },
        "test": {
            "0": {
                "precision": 0.7112568306010929,
                "recall": 0.7039480800432666,
                "f1-score": 0.7075835824952431,
                "support": 9245
            },
            "1": {
                "precision": 0.7383365200764819,
                "recall": 0.7451037144235407,
                "f1-score": 0.7417046818727491,
                "support": 10365
            },
            "accuracy": 0.7257011728709842,
            "macro avg": {
                "precision": 0.7247966753387873,
                "recall": 0.7245258972334037,
                "f1-score": 0.724644132183996,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7255699862060091,
                "recall": 0.7257011728709842,
                "f1-score": 0.725618523599162,
                "support": 19610
            },
            "roc_auc": 0.8046234245600743,
            "score": 0.7257011728709842
        }
    },
    "time": "0:00:06"
}
