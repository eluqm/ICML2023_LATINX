{
    "config": {
        "data": {
            "path": "data/higgs_small",
            "y_policy": "mean_std"
        },
        "fit": {
            "early_stopping_rounds": 50,
            "verbose": true
        },
        "model": {
            "colsample_bytree": 0.7999440674588046,
            "learning_rate": 0.04183849804413404,
            "min_child_samples": 81,
            "min_child_weight": 0.00676057460469568,
            "n_estimators": 2000,
            "n_jobs": 1,
            "num_leaves": 94,
            "reg_lambda": 0.006637134146517112,
            "subsample": 0.6165566522563218
        },
        "seed": 1
    },
    "environment": {},
    "dataset": "higgs_small",
    "algorithm": "lightgbm_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.7903484522712535,
                "recall": 0.7828409167737137,
                "f1-score": 0.7865767708846356,
                "support": 29582
            },
            "1": {
                "precision": 0.8079579085827031,
                "recall": 0.8148025324088032,
                "f1-score": 0.8113657855631108,
                "support": 33170
            },
            "accuracy": 0.7997354665986741,
            "macro avg": {
                "precision": 0.7991531804269782,
                "recall": 0.7988217245912584,
                "f1-score": 0.7989712782238731,
                "support": 62752
            },
            "weighted avg": {
                "precision": 0.7996566124231337,
                "recall": 0.7997354665986741,
                "f1-score": 0.7996799646774234,
                "support": 62752
            },
            "roc_auc": 0.8840934424940066,
            "score": 0.7997354665986741
        },
        "val": {
            "0": {
                "precision": 0.7184891200218968,
                "recall": 0.7098431584640346,
                "f1-score": 0.7141399714344011,
                "support": 7396
            },
            "1": {
                "precision": 0.7439446366782007,
                "recall": 0.7519295706705258,
                "f1-score": 0.7479157919990405,
                "support": 8292
            },
            "accuracy": 0.7320882202957675,
            "macro avg": {
                "precision": 0.7312168783500488,
                "recall": 0.7308863645672802,
                "f1-score": 0.7310278817167208,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.7319438079434976,
                "recall": 0.7320882202957675,
                "f1-score": 0.7319924130535997,
                "support": 15688
            },
            "roc_auc": 0.8098611568762348,
            "score": 0.7320882202957675
        },
        "test": {
            "0": {
                "precision": 0.7112528874711253,
                "recall": 0.6994050838290968,
                "f1-score": 0.7052792321116929,
                "support": 9245
            },
            "1": {
                "precision": 0.7358113889152962,
                "recall": 0.7467438494934877,
                "f1-score": 0.7412373108599886,
                "support": 10365
            },
            "accuracy": 0.7244263131055584,
            "macro avg": {
                "precision": 0.7235321381932107,
                "recall": 0.7230744666612923,
                "f1-score": 0.7232582714858407,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7242334518499539,
                "recall": 0.7244263131055584,
                "f1-score": 0.7242851212614168,
                "support": 19610
            },
            "roc_auc": 0.8032676011361404,
            "score": 0.7244263131055584
        }
    },
    "time": "0:00:06"
}
