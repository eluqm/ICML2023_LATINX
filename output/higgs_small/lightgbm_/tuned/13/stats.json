{
    "config": {
        "data": {
            "path": "data/higgs_small",
            "y_policy": "mean_std"
        },
        "fit": {
            "early_stopping_rounds": 50,
            "verbose": true
        },
        "model": {
            "colsample_bytree": 0.7999440674588046,
            "learning_rate": 0.04183849804413404,
            "min_child_samples": 81,
            "min_child_weight": 0.00676057460469568,
            "n_estimators": 2000,
            "n_jobs": 1,
            "num_leaves": 94,
            "reg_lambda": 0.006637134146517112,
            "subsample": 0.6165566522563218
        },
        "seed": 13
    },
    "environment": {},
    "dataset": "higgs_small",
    "algorithm": "lightgbm_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.7674837656818414,
                "recall": 0.7630991819349604,
                "f1-score": 0.7652851936604796,
                "support": 29582
            },
            "1": {
                "precision": 0.7897957347250968,
                "recall": 0.7938197166113958,
                "f1-score": 0.7918026131801711,
                "support": 33170
            },
            "accuracy": 0.7793377103518613,
            "macro avg": {
                "precision": 0.7786397502034691,
                "recall": 0.7784594492731781,
                "f1-score": 0.7785439034203254,
                "support": 62752
            },
            "weighted avg": {
                "precision": 0.7792776210675626,
                "recall": 0.7793377103518613,
                "f1-score": 0.779302002773626,
                "support": 62752
            },
            "roc_auc": 0.8636002902627988,
            "score": 0.7793377103518613
        },
        "val": {
            "0": {
                "precision": 0.7117336581404791,
                "recall": 0.711060032449973,
                "f1-score": 0.7113966858302333,
                "support": 7396
            },
            "1": {
                "precision": 0.7424990962766599,
                "recall": 0.7431259044862518,
                "f1-score": 0.7428123681514074,
                "support": 8292
            },
            "accuracy": 0.7280086690464049,
            "macro avg": {
                "precision": 0.7271163772085695,
                "recall": 0.7270929684681124,
                "f1-score": 0.7271045269908203,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.727994941479669,
                "recall": 0.7280086690464049,
                "f1-score": 0.7280016601932607,
                "support": 15688
            },
            "roc_auc": 0.8067253273369499,
            "score": 0.7280086690464049
        },
        "test": {
            "0": {
                "precision": 0.7074829931972789,
                "recall": 0.6974580854515955,
                "f1-score": 0.7024347731357916,
                "support": 9245
            },
            "1": {
                "precision": 0.7335175304878049,
                "recall": 0.7427882296189098,
                "f1-score": 0.7381237716312737,
                "support": 10365
            },
            "accuracy": 0.7214176440591535,
            "macro avg": {
                "precision": 0.7205002618425419,
                "recall": 0.7201231575352527,
                "f1-score": 0.7202792723835327,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7212437264464528,
                "recall": 0.7214176440591535,
                "f1-score": 0.7212984380723378,
                "support": 19610
            },
            "roc_auc": 0.8011643899767726,
            "score": 0.7214176440591535
        }
    },
    "time": "0:00:05"
}
