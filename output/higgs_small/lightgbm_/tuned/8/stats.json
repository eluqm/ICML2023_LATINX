{
    "config": {
        "data": {
            "path": "data/higgs_small",
            "y_policy": "mean_std"
        },
        "fit": {
            "early_stopping_rounds": 50,
            "verbose": true
        },
        "model": {
            "colsample_bytree": 0.7999440674588046,
            "learning_rate": 0.04183849804413404,
            "min_child_samples": 81,
            "min_child_weight": 0.00676057460469568,
            "n_estimators": 2000,
            "n_jobs": 1,
            "num_leaves": 94,
            "reg_lambda": 0.006637134146517112,
            "subsample": 0.6165566522563218
        },
        "seed": 8
    },
    "environment": {},
    "dataset": "higgs_small",
    "algorithm": "lightgbm_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.7861275610918249,
                "recall": 0.7808126563450747,
                "f1-score": 0.783461094905366,
                "support": 29582
            },
            "1": {
                "precision": 0.8056937368894216,
                "recall": 0.8105517033463974,
                "f1-score": 0.8081154192966635,
                "support": 33170
            },
            "accuracy": 0.7965323814380418,
            "macro avg": {
                "precision": 0.7959106489906232,
                "recall": 0.7956821798457361,
                "f1-score": 0.7957882571010148,
                "support": 62752
            },
            "weighted avg": {
                "precision": 0.7964700211123228,
                "recall": 0.7965323814380418,
                "f1-score": 0.796493092930279,
                "support": 62752
            },
            "roc_auc": 0.8812427653666715,
            "score": 0.7965323814380418
        },
        "val": {
            "0": {
                "precision": 0.7110841096260294,
                "recall": 0.7121416982152515,
                "f1-score": 0.7116125109775046,
                "support": 7396
            },
            "1": {
                "precision": 0.7429054462021495,
                "recall": 0.7419199228171732,
                "f1-score": 0.7424123574488626,
                "support": 8292
            },
            "accuracy": 0.7278811830698623,
            "macro avg": {
                "precision": 0.7269947779140895,
                "recall": 0.7270308105162124,
                "f1-score": 0.7270124342131836,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.7279034953277879,
                "recall": 0.7278811830698623,
                "f1-score": 0.7278919810782504,
                "support": 15688
            },
            "roc_auc": 0.8078076127250438,
            "score": 0.7278811830698623
        },
        "test": {
            "0": {
                "precision": 0.7112961542675578,
                "recall": 0.7022174148188209,
                "f1-score": 0.7067276290006531,
                "support": 9245
            },
            "1": {
                "precision": 0.7373843365448822,
                "recall": 0.7457790641582248,
                "f1-score": 0.7415579432079817,
                "support": 10365
            },
            "accuracy": 0.7252422233554309,
            "macro avg": {
                "precision": 0.72434024540622,
                "recall": 0.7239982394885229,
                "f1-score": 0.7241427861043175,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7250852419424414,
                "recall": 0.7252422233554309,
                "f1-score": 0.7251374304671988,
                "support": 19610
            },
            "roc_auc": 0.802706230692227,
            "score": 0.7252422233554309
        }
    },
    "time": "0:00:05"
}
