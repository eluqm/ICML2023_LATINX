{
    "config": {
        "data": {
            "path": "data/higgs_small",
            "y_policy": "mean_std"
        },
        "fit": {
            "early_stopping_rounds": 50,
            "verbose": true
        },
        "model": {
            "colsample_bytree": 0.7999440674588046,
            "learning_rate": 0.04183849804413404,
            "min_child_samples": 81,
            "min_child_weight": 0.00676057460469568,
            "n_estimators": 2000,
            "n_jobs": 1,
            "num_leaves": 94,
            "reg_lambda": 0.006637134146517112,
            "subsample": 0.6165566522563218
        },
        "seed": 7
    },
    "environment": {},
    "dataset": "higgs_small",
    "algorithm": "lightgbm_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.7856096480768575,
                "recall": 0.7795280914069367,
                "f1-score": 0.7825570543819461,
                "support": 29582
            },
            "1": {
                "precision": 0.8047246923560586,
                "recall": 0.8102803738317756,
                "f1-score": 0.807492977211615,
                "support": 33170
            },
            "accuracy": 0.7957834013258541,
            "macro avg": {
                "precision": 0.795167170216458,
                "recall": 0.7949042326193562,
                "f1-score": 0.7950250157967805,
                "support": 62752
            },
            "weighted avg": {
                "precision": 0.7957136450608755,
                "recall": 0.7957834013258541,
                "f1-score": 0.7957379021678352,
                "support": 62752
            },
            "roc_auc": 0.8798434144630032,
            "score": 0.7957834013258541
        },
        "val": {
            "0": {
                "precision": 0.7102550189907759,
                "recall": 0.7079502433747972,
                "f1-score": 0.7091007583965331,
                "support": 7396
            },
            "1": {
                "precision": 0.7402597402597403,
                "recall": 0.7424023154848046,
                "f1-score": 0.7413294797687862,
                "support": 8292
            },
            "accuracy": 0.7261601223865375,
            "macro avg": {
                "precision": 0.7252573796252582,
                "recall": 0.7251762794298009,
                "f1-score": 0.7252151190826597,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.7261142202122353,
                "recall": 0.7261601223865375,
                "f1-score": 0.7261354701264364,
                "support": 15688
            },
            "roc_auc": 0.8085362402383317,
            "score": 0.7261601223865375
        },
        "test": {
            "0": {
                "precision": 0.7082742832225009,
                "recall": 0.7027582477014602,
                "f1-score": 0.7055054837658812,
                "support": 9245
            },
            "1": {
                "precision": 0.7367059499856281,
                "recall": 0.7418234442836469,
                "f1-score": 0.73925584078454,
                "support": 10365
            },
            "accuracy": 0.7234064252932177,
            "macro avg": {
                "precision": 0.7224901166040645,
                "recall": 0.7222908459925536,
                "f1-score": 0.7223806622752106,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7233020356957193,
                "recall": 0.7234064252932177,
                "f1-score": 0.7233444664532039,
                "support": 19610
            },
            "roc_auc": 0.8035051814816525,
            "score": 0.7234064252932177
        }
    },
    "time": "0:00:05"
}
