{
    "config": {
        "data": {
            "path": "data/higgs_small",
            "y_policy": "mean_std"
        },
        "fit": {
            "early_stopping_rounds": 50,
            "verbose": true
        },
        "model": {
            "colsample_bytree": 0.7999440674588046,
            "learning_rate": 0.04183849804413404,
            "min_child_samples": 81,
            "min_child_weight": 0.00676057460469568,
            "n_estimators": 2000,
            "n_jobs": 1,
            "num_leaves": 94,
            "reg_lambda": 0.006637134146517112,
            "subsample": 0.6165566522563218
        },
        "seed": 10
    },
    "environment": {},
    "dataset": "higgs_small",
    "algorithm": "lightgbm_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.7850037473598147,
                "recall": 0.7789534176188223,
                "f1-score": 0.7819668793267274,
                "support": 29582
            },
            "1": {
                "precision": 0.8042098329241272,
                "recall": 0.8097377148025324,
                "f1-score": 0.8069643071746184,
                "support": 33170
            },
            "accuracy": 0.7952256501784803,
            "macro avg": {
                "precision": 0.7946067901419709,
                "recall": 0.7943455662106773,
                "f1-score": 0.7944655932506729,
                "support": 62752
            },
            "weighted avg": {
                "precision": 0.7951558677411291,
                "recall": 0.7952256501784803,
                "f1-score": 0.7951802379721019,
                "support": 62752
            },
            "roc_auc": 0.8798262045173402,
            "score": 0.7952256501784803
        },
        "val": {
            "0": {
                "precision": 0.7126530612244898,
                "recall": 0.7082206598161168,
                "f1-score": 0.7104299471042994,
                "support": 7396
            },
            "1": {
                "precision": 0.741184936435596,
                "recall": 0.7452966714905933,
                "f1-score": 0.7432351172579674,
                "support": 8292
            },
            "accuracy": 0.727817440081591,
            "macro avg": {
                "precision": 0.7269189988300429,
                "recall": 0.7267586656533551,
                "f1-score": 0.7268325321811334,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.7277337795601918,
                "recall": 0.727817440081591,
                "f1-score": 0.727769344791335,
                "support": 15688
            },
            "roc_auc": 0.808266720619508,
            "score": 0.727817440081591
        },
        "test": {
            "0": {
                "precision": 0.7123513870541611,
                "recall": 0.6999459167117361,
                "f1-score": 0.7060941677123684,
                "support": 9245
            },
            "1": {
                "precision": 0.7364620938628159,
                "recall": 0.7479015918958032,
                "f1-score": 0.7421377626729213,
                "support": 10365
            },
            "accuracy": 0.7252932177460479,
            "macro avg": {
                "precision": 0.7244067404584885,
                "recall": 0.7239237543037697,
                "f1-score": 0.7241159651926449,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7250952665070783,
                "recall": 0.7252932177460479,
                "f1-score": 0.7251452570426148,
                "support": 19610
            },
            "roc_auc": 0.8036067004837233,
            "score": 0.7252932177460479
        }
    },
    "time": "0:00:06"
}
