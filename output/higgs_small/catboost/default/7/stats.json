{
    "config": {
        "data": {
            "path": "data/higgs_small"
        },
        "fit": {
            "logging_level": "Verbose"
        },
        "model": {
            "iterations": 2000,
            "task_type": "CPU",
            "thread_count": 10
        },
        "seed": 7
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "dataset": "higgs_small",
    "algorithm": "catboost_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8440239320996243,
                "recall": 0.8202285173416267,
                "f1-score": 0.8319561117778158,
                "support": 29582
            },
            "1": {
                "precision": 0.8436066345135866,
                "recall": 0.8648176062707266,
                "f1-score": 0.8540804477923005,
                "support": 33170
            },
            "accuracy": 0.8437978072412035,
            "macro avg": {
                "precision": 0.8438152833066055,
                "recall": 0.8425230618061766,
                "f1-score": 0.8430182797850582,
                "support": 62752
            },
            "weighted avg": {
                "precision": 0.8438033532984885,
                "recall": 0.8437978072412035,
                "f1-score": 0.8436507864591081,
                "support": 62752
            },
            "roc_auc": 0.9226472500051823,
            "score": 0.8437978072412035
        },
        "val": {
            "0": {
                "precision": 0.7244655581947743,
                "recall": 0.7010546241211466,
                "f1-score": 0.7125678554249983,
                "support": 7396
            },
            "1": {
                "precision": 0.7408275700386825,
                "recall": 0.7621804148576942,
                "f1-score": 0.7513523152826488,
                "support": 8292
            },
            "accuracy": 0.7333630800611932,
            "macro avg": {
                "precision": 0.7326465641167283,
                "recall": 0.7316175194894203,
                "f1-score": 0.7319600853538235,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.7331138117777477,
                "recall": 0.7333630800611932,
                "f1-score": 0.7330676476955005,
                "support": 15688
            },
            "roc_auc": 0.8103914887827398,
            "score": 0.7333630800611932
        },
        "test": {
            "0": {
                "precision": 0.715840924239058,
                "recall": 0.697025419145484,
                "f1-score": 0.7063078862278731,
                "support": 9245
            },
            "1": {
                "precision": 0.7359539969834088,
                "recall": 0.7532079112397492,
                "f1-score": 0.7444809993801556,
                "support": 10365
            },
            "accuracy": 0.7267210606833249,
            "macro avg": {
                "precision": 0.7258974606112334,
                "recall": 0.7251166651926166,
                "f1-score": 0.7253944428040143,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7264718267885325,
                "recall": 0.7267210606833249,
                "f1-score": 0.7264845470041815,
                "support": 19610
            },
            "roc_auc": 0.8042201975122731,
            "score": 0.7267210606833249
        }
    }
}
