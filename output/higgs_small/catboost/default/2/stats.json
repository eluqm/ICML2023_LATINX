{
    "config": {
        "data": {
            "path": "data/higgs_small"
        },
        "fit": {
            "logging_level": "Verbose"
        },
        "model": {
            "iterations": 2000,
            "task_type": "CPU",
            "thread_count": 10
        },
        "seed": 2
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "dataset": "higgs_small",
    "algorithm": "catboost_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8153034300791556,
                "recall": 0.7938611317693192,
                "f1-score": 0.8044394204090022,
                "support": 29582
            },
            "1": {
                "precision": 0.8203723341581242,
                "recall": 0.8396141091347603,
                "f1-score": 0.8298817008850085,
                "support": 33170
            },
            "accuracy": 0.8180456399796022,
            "macro avg": {
                "precision": 0.8178378821186398,
                "recall": 0.8167376204520398,
                "f1-score": 0.8171605606470054,
                "support": 62752
            },
            "weighted avg": {
                "precision": 0.8179827956499643,
                "recall": 0.8180456399796022,
                "f1-score": 0.817887923140216,
                "support": 62752
            },
            "roc_auc": 0.9002932946925026,
            "score": 0.8180456399796022
        },
        "val": {
            "0": {
                "precision": 0.7225,
                "recall": 0.7033531638723635,
                "f1-score": 0.712798026856673,
                "support": 7396
            },
            "1": {
                "precision": 0.7415174363807728,
                "recall": 0.7590448625180898,
                "f1-score": 0.7501787842669845,
                "support": 8292
            },
            "accuracy": 0.7327893931667516,
            "macro avg": {
                "precision": 0.7320087181903865,
                "recall": 0.7311990131952266,
                "f1-score": 0.7314884055618287,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.7325517964348145,
                "recall": 0.7327893931667516,
                "f1-score": 0.7325558825709962,
                "support": 15688
            },
            "roc_auc": 0.8106128897981908,
            "score": 0.7327893931667516
        },
        "test": {
            "0": {
                "precision": 0.7140950050061186,
                "recall": 0.6943212547322877,
                "f1-score": 0.7040693210485904,
                "support": 9245
            },
            "1": {
                "precision": 0.7339233593823558,
                "recall": 0.7520501688374337,
                "f1-score": 0.7428762031830745,
                "support": 10365
            },
            "accuracy": 0.7248342682304947,
            "macro avg": {
                "precision": 0.7240091821942372,
                "recall": 0.7231857117848607,
                "f1-score": 0.7234727621158324,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7245754177093159,
                "recall": 0.7248342682304947,
                "f1-score": 0.7245809647673017,
                "support": 19610
            },
            "roc_auc": 0.8042554181775678,
            "score": 0.7248342682304947
        }
    }
}
