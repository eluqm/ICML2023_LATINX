{
    "config": {
        "data": {
            "path": "data/higgs_small"
        },
        "fit": {
            "logging_level": "Verbose"
        },
        "model": {
            "iterations": 2000,
            "task_type": "CPU",
            "thread_count": 10
        },
        "seed": 13
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "dataset": "higgs_small",
    "algorithm": "catboost_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8118512861457284,
                "recall": 0.7905821107430194,
                "f1-score": 0.801075545051294,
                "support": 29582
            },
            "1": {
                "precision": 0.8174988952717631,
                "recall": 0.8365993367500754,
                "f1-score": 0.8269388363257095,
                "support": 33170
            },
            "accuracy": 0.8149062978072412,
            "macro avg": {
                "precision": 0.8146750907087458,
                "recall": 0.8135907237465474,
                "f1-score": 0.8140071906885018,
                "support": 62752
            },
            "weighted avg": {
                "precision": 0.8148365486825491,
                "recall": 0.8149062978072412,
                "f1-score": 0.8147465893458561,
                "support": 62752
            },
            "roc_auc": 0.8971524016460319,
            "score": 0.8149062978072412
        },
        "val": {
            "0": {
                "precision": 0.7192982456140351,
                "recall": 0.7040292049756626,
                "f1-score": 0.7115818243935772,
                "support": 7396
            },
            "1": {
                "precision": 0.7409160847437567,
                "recall": 0.7549445248432224,
                "f1-score": 0.74786452422197,
                "support": 8292
            },
            "accuracy": 0.7309408465068843,
            "macro avg": {
                "precision": 0.730107165178896,
                "recall": 0.7294868649094425,
                "f1-score": 0.7297231743077737,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.730724502757307,
                "recall": 0.7309408465068843,
                "f1-score": 0.7307592942416797,
                "support": 15688
            },
            "roc_auc": 0.8108985848336684,
            "score": 0.7309408465068843
        },
        "test": {
            "0": {
                "precision": 0.7164627363737486,
                "recall": 0.6967009194159005,
                "f1-score": 0.7064436523169728,
                "support": 9245
            },
            "1": {
                "precision": 0.735969868173258,
                "recall": 0.7540762180414857,
                "f1-score": 0.7449130331188945,
                "support": 10365
            },
            "accuracy": 0.727027027027027,
            "macro avg": {
                "precision": 0.7262163022735033,
                "recall": 0.7253885687286932,
                "f1-score": 0.7256783427179336,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7267733646808325,
                "recall": 0.727027027027027,
                "f1-score": 0.7267769073915223,
                "support": 19610
            },
            "roc_auc": 0.8044911305233504,
            "score": 0.727027027027027
        }
    }
}
