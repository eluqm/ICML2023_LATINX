{
    "config": {
        "data": {
            "path": "data/higgs_small"
        },
        "fit": {
            "logging_level": "Verbose"
        },
        "model": {
            "iterations": 2000,
            "task_type": "CPU",
            "thread_count": 10
        },
        "seed": 3
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "dataset": "higgs_small",
    "algorithm": "catboost_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8196322430393826,
                "recall": 0.7971063484551416,
                "f1-score": 0.8082123699679525,
                "support": 29582
            },
            "1": {
                "precision": 0.8233822793749817,
                "recall": 0.8435634609586976,
                "f1-score": 0.8333507065953866,
                "support": 33170
            },
            "accuracy": 0.8216630545639979,
            "macro avg": {
                "precision": 0.8215072612071821,
                "recall": 0.8203349047069196,
                "f1-score": 0.8207815382816696,
                "support": 62752
            },
            "weighted avg": {
                "precision": 0.8216144699843696,
                "recall": 0.8216630545639979,
                "f1-score": 0.8215002114061855,
                "support": 62752
            },
            "roc_auc": 0.9039244097850816,
            "score": 0.8216630545639979
        },
        "val": {
            "0": {
                "precision": 0.7209463198671832,
                "recall": 0.7045700378583017,
                "f1-score": 0.712664113785558,
                "support": 7396
            },
            "1": {
                "precision": 0.741725768321513,
                "recall": 0.7567534973468403,
                "f1-score": 0.7491642788920726,
                "support": 8292
            },
            "accuracy": 0.7321519632840388,
            "macro avg": {
                "precision": 0.7313360440943482,
                "recall": 0.7306617676025711,
                "f1-score": 0.7309141963388153,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.7319294398686685,
                "recall": 0.7321519632840388,
                "f1-score": 0.731956526397951,
                "support": 15688
            },
            "roc_auc": 0.8105029556660528,
            "score": 0.7321519632840388
        },
        "test": {
            "0": {
                "precision": 0.7159697508896797,
                "recall": 0.6963764196863169,
                "f1-score": 0.7060371771672972,
                "support": 9245
            },
            "1": {
                "precision": 0.7356375965341873,
                "recall": 0.7535938253738543,
                "f1-score": 0.7445074584187199,
                "support": 10365
            },
            "accuracy": 0.7266190719020907,
            "macro avg": {
                "precision": 0.7258036737119336,
                "recall": 0.7249851225300856,
                "f1-score": 0.7252723177930085,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7263653256018329,
                "recall": 0.7266190719020907,
                "f1-score": 0.7263709081806066,
                "support": 19610
            },
            "roc_auc": 0.8039636032253781,
            "score": 0.7266190719020907
        }
    }
}
