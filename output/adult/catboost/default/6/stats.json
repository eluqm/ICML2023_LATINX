{
    "config": {
        "data": {
            "cat_policy": "indices",
            "path": "data/adult"
        },
        "fit": {
            "logging_level": "Verbose"
        },
        "model": {
            "iterations": 2000,
            "task_type": "CPU",
            "thread_count": 10
        },
        "seed": 6
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "dataset": "adult",
    "algorithm": "catboost_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9119091171656879,
                "recall": 0.9579772439949431,
                "f1-score": 0.9343756936052678,
                "support": 19775
            },
            "1": {
                "precision": 0.8424345847554039,
                "recall": 0.7082735533237685,
                "f1-score": 0.7695505326058717,
                "support": 6273
            },
            "accuracy": 0.8978424447174447,
            "macro avg": {
                "precision": 0.877171850960546,
                "recall": 0.8331253986593559,
                "f1-score": 0.8519631131055698,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8951779385028459,
                "recall": 0.8978424447174447,
                "f1-score": 0.894681734953962,
                "support": 26048
            },
            "roc_auc": 0.9547175209388743,
            "score": 0.8978424447174447
        },
        "val": {
            "0": {
                "precision": 0.8947669977081741,
                "recall": 0.9474216380182002,
                "f1-score": 0.9203418131814163,
                "support": 4945
            },
            "1": {
                "precision": 0.7963978073610023,
                "recall": 0.6485969387755102,
                "f1-score": 0.7149384885764498,
                "support": 1568
            },
            "accuracy": 0.8754798096115461,
            "macro avg": {
                "precision": 0.8455824025345882,
                "recall": 0.7980092883968553,
                "f1-score": 0.817640150878933,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8710846868737866,
                "recall": 0.8754798096115461,
                "f1-score": 0.8708911125855945,
                "support": 6513
            },
            "roc_auc": 0.926081991188791,
            "score": 0.8754798096115461
        },
        "test": {
            "0": {
                "precision": 0.8953151228444987,
                "recall": 0.9436268596702855,
                "f1-score": 0.9188363807211933,
                "support": 12435
            },
            "1": {
                "precision": 0.7792125984251969,
                "recall": 0.6432657306292252,
                "f1-score": 0.7047429141147985,
                "support": 3846
            },
            "accuracy": 0.8726736686935692,
            "macro avg": {
                "precision": 0.8372638606348477,
                "recall": 0.7934462951497554,
                "f1-score": 0.811789647417996,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8678886558635618,
                "recall": 0.8726736686935692,
                "f1-score": 0.8682618783829958,
                "support": 16281
            },
            "roc_auc": 0.9280013846311794,
            "score": 0.8726736686935692
        }
    }
}
