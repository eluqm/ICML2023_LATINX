{
    "config": {
        "data": {
            "cat_policy": "indices",
            "path": "data/adult"
        },
        "fit": {
            "logging_level": "Verbose"
        },
        "model": {
            "iterations": 2000,
            "task_type": "CPU",
            "thread_count": 10
        },
        "seed": 12
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "dataset": "adult",
    "algorithm": "catboost_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9101356897967068,
                "recall": 0.9531226295828066,
                "f1-score": 0.9311332872245826,
                "support": 19775
            },
            "1": {
                "precision": 0.8263719797714928,
                "recall": 0.7033317391997449,
                "f1-score": 0.7599035480537375,
                "support": 6273
            },
            "accuracy": 0.8929668304668305,
            "macro avg": {
                "precision": 0.8682538347840998,
                "recall": 0.8282271843912757,
                "f1-score": 0.84551841763916,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8899633252010307,
                "recall": 0.8929668304668305,
                "f1-score": 0.8898969483955472,
                "support": 26048
            },
            "roc_auc": 0.9495749265962949,
            "score": 0.8929668304668305
        },
        "val": {
            "0": {
                "precision": 0.8963332693415242,
                "recall": 0.9441860465116279,
                "f1-score": 0.9196375812487688,
                "support": 4945
            },
            "1": {
                "precision": 0.7883435582822086,
                "recall": 0.6556122448979592,
                "f1-score": 0.7158774373259054,
                "support": 1568
            },
            "accuracy": 0.8747121142330723,
            "macro avg": {
                "precision": 0.8423384138118664,
                "recall": 0.7998991457047935,
                "f1-score": 0.817757509287337,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.870334825162036,
                "recall": 0.8747121142330723,
                "f1-score": 0.8705824752037742,
                "support": 6513
            },
            "roc_auc": 0.9269326107591672,
            "score": 0.8747121142330723
        },
        "test": {
            "0": {
                "precision": 0.8975501113585747,
                "recall": 0.9398472054684359,
                "f1-score": 0.9182118164676305,
                "support": 12435
            },
            "1": {
                "precision": 0.7705521472392638,
                "recall": 0.6531461258450338,
                "f1-score": 0.7070081621165213,
                "support": 3846
            },
            "accuracy": 0.8721208770960015,
            "macro avg": {
                "precision": 0.8340511292989192,
                "recall": 0.7964966656567349,
                "f1-score": 0.812609989292076,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8675498552316249,
                "recall": 0.8721208770960015,
                "f1-score": 0.868319963716917,
                "support": 16281
            },
            "roc_auc": 0.9277750490799689,
            "score": 0.8721208770960015
        }
    }
}
