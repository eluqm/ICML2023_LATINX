{
    "config": {
        "data": {
            "cat_policy": "indices",
            "path": "data/adult"
        },
        "fit": {
            "logging_level": "Verbose"
        },
        "model": {
            "iterations": 2000,
            "task_type": "CPU",
            "thread_count": 10
        },
        "seed": 8
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "dataset": "adult",
    "algorithm": "catboost_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9121171127645183,
                "recall": 0.9546902654867256,
                "f1-score": 0.9329182417908235,
                "support": 19775
            },
            "1": {
                "precision": 0.8325233644859813,
                "recall": 0.7100271002710027,
                "f1-score": 0.7664114256216125,
                "support": 6273
            },
            "accuracy": 0.8957693488943489,
            "macro avg": {
                "precision": 0.8723202386252498,
                "recall": 0.8323586828788642,
                "f1-score": 0.849664833706218,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.892948977669645,
                "recall": 0.8957693488943489,
                "f1-score": 0.8928192991530216,
                "support": 26048
            },
            "roc_auc": 0.9526976509000605,
            "score": 0.8957693488943489
        },
        "val": {
            "0": {
                "precision": 0.8955738647250431,
                "recall": 0.9451971688574318,
                "f1-score": 0.9197166469893743,
                "support": 4945
            },
            "1": {
                "precision": 0.7905718701700154,
                "recall": 0.6524234693877551,
                "f1-score": 0.7148846960167713,
                "support": 1568
            },
            "accuracy": 0.8747121142330723,
            "macro avg": {
                "precision": 0.8430728674475292,
                "recall": 0.7988103191225935,
                "f1-score": 0.8173006715030728,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8702947111149889,
                "recall": 0.8747121142330723,
                "f1-score": 0.870403504178835,
                "support": 6513
            },
            "roc_auc": 0.9267547615608427,
            "score": 0.8747121142330723
        },
        "test": {
            "0": {
                "precision": 0.8963639153114452,
                "recall": 0.9396863691194209,
                "f1-score": 0.9175140355698638,
                "support": 12435
            },
            "1": {
                "precision": 0.7688751926040062,
                "recall": 0.6487259490379615,
                "f1-score": 0.7037089268086306,
                "support": 3846
            },
            "accuracy": 0.8709538726122474,
            "macro avg": {
                "precision": 0.8326195539577257,
                "recall": 0.7942061590786913,
                "f1-score": 0.8106114811892472,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8662477291107934,
                "recall": 0.8709538726122474,
                "f1-score": 0.867007650931592,
                "support": 16281
            },
            "roc_auc": 0.927715164095104,
            "score": 0.8709538726122474
        }
    }
}
