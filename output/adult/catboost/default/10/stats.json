{
    "config": {
        "data": {
            "cat_policy": "indices",
            "path": "data/adult"
        },
        "fit": {
            "logging_level": "Verbose"
        },
        "model": {
            "iterations": 2000,
            "task_type": "CPU",
            "thread_count": 10
        },
        "seed": 10
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "dataset": "adult",
    "algorithm": "catboost_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9085206986393901,
                "recall": 0.952212389380531,
                "f1-score": 0.9298535838621268,
                "support": 19775
            },
            "1": {
                "precision": 0.822435174746336,
                "recall": 0.6977522716403635,
                "f1-score": 0.754980595084088,
                "support": 6273
            },
            "accuracy": 0.8909321253071253,
            "macro avg": {
                "precision": 0.8654779366928631,
                "recall": 0.8249823305104472,
                "f1-score": 0.8424170894731073,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8877891840746969,
                "recall": 0.8909321253071253,
                "f1-score": 0.8877398607891601,
                "support": 26048
            },
            "roc_auc": 0.9467334872649685,
            "score": 0.8909321253071253
        },
        "val": {
            "0": {
                "precision": 0.8970278044103548,
                "recall": 0.9460060667340748,
                "f1-score": 0.9208661417322835,
                "support": 4945
            },
            "1": {
                "precision": 0.7942989214175655,
                "recall": 0.6575255102040817,
                "f1-score": 0.71946964410328,
                "support": 1568
            },
            "accuracy": 0.8765545831414094,
            "macro avg": {
                "precision": 0.8456633629139602,
                "recall": 0.8017657884690783,
                "f1-score": 0.8201678929177818,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8722959007511051,
                "recall": 0.8765545831414094,
                "f1-score": 0.8723800818087034,
                "support": 6513
            },
            "roc_auc": 0.9268396236148657,
            "score": 0.8765545831414094
        },
        "test": {
            "0": {
                "precision": 0.8989844591475612,
                "recall": 0.9396863691194209,
                "f1-score": 0.918884913301616,
                "support": 12435
            },
            "1": {
                "precision": 0.7715504112092598,
                "recall": 0.6586063442537702,
                "f1-score": 0.7106186000841632,
                "support": 3846
            },
            "accuracy": 0.8732878815797556,
            "macro avg": {
                "precision": 0.8352674351784105,
                "recall": 0.7991463566865955,
                "f1-score": 0.8147517566928897,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8688811885640155,
                "recall": 0.8732878815797556,
                "f1-score": 0.869686937708328,
                "support": 16281
            },
            "roc_auc": 0.9279429528608567,
            "score": 0.8732878815797556
        }
    }
}
