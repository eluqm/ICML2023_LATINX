{
    "config": {
        "data": {
            "cat_policy": "indices",
            "path": "data/adult"
        },
        "fit": {
            "logging_level": "Verbose"
        },
        "model": {
            "iterations": 2000,
            "task_type": "CPU",
            "thread_count": 10
        },
        "seed": 3
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "dataset": "adult",
    "algorithm": "catboost_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9125587707818331,
                "recall": 0.9520606826801518,
                "f1-score": 0.9318913032717914,
                "support": 19775
            },
            "1": {
                "precision": 0.8249953848993908,
                "recall": 0.7124183006535948,
                "f1-score": 0.7645851154833191,
                "support": 6273
            },
            "accuracy": 0.8943488943488943,
            "macro avg": {
                "precision": 0.868777077840612,
                "recall": 0.8322394916668733,
                "f1-score": 0.8482382093775552,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8914713506482121,
                "recall": 0.8943488943488943,
                "f1-score": 0.8915998522583897,
                "support": 26048
            },
            "roc_auc": 0.9502271589979973,
            "score": 0.8943488943488943
        },
        "val": {
            "0": {
                "precision": 0.8972879399884593,
                "recall": 0.9433771486349848,
                "f1-score": 0.9197555205047319,
                "support": 4945
            },
            "1": {
                "precision": 0.786910197869102,
                "recall": 0.6594387755102041,
                "f1-score": 0.717557251908397,
                "support": 1568
            },
            "accuracy": 0.8750191923844618,
            "macro avg": {
                "precision": 0.8420990689287806,
                "recall": 0.8014079620725945,
                "f1-score": 0.8186563862065644,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8707145790728824,
                "recall": 0.8750191923844618,
                "f1-score": 0.8710764348055068,
                "support": 6513
            },
            "roc_auc": 0.9268269201006996,
            "score": 0.8750191923844618
        },
        "test": {
            "0": {
                "precision": 0.8992295839753467,
                "recall": 0.9386409328508243,
                "f1-score": 0.9185126893566792,
                "support": 12435
            },
            "1": {
                "precision": 0.7688579218418661,
                "recall": 0.6599063962558502,
                "f1-score": 0.710228067720722,
                "support": 3846
            },
            "accuracy": 0.8727965112708065,
            "macro avg": {
                "precision": 0.8340437529086064,
                "recall": 0.7992736645533373,
                "f1-score": 0.8143703785387006,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8684323717300689,
                "recall": 0.8727965112708065,
                "f1-score": 0.8693103888338679,
                "support": 16281
            },
            "roc_auc": 0.9278900307600563,
            "score": 0.8727965112708065
        }
    }
}
