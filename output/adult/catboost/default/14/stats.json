{
    "config": {
        "data": {
            "cat_policy": "indices",
            "path": "data/adult"
        },
        "fit": {
            "logging_level": "Verbose"
        },
        "model": {
            "iterations": 2000,
            "task_type": "CPU",
            "thread_count": 10
        },
        "seed": 14
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "dataset": "adult",
    "algorithm": "catboost_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9090909090909091,
                "recall": 0.9506953223767383,
                "f1-score": 0.9294277592386602,
                "support": 19775
            },
            "1": {
                "precision": 0.8183681073025335,
                "recall": 0.700302885381795,
                "f1-score": 0.7547461558285371,
                "support": 6273
            },
            "accuracy": 0.8903946560196561,
            "macro avg": {
                "precision": 0.8637295081967213,
                "recall": 0.8254991038792666,
                "f1-score": 0.8420869575335986,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8872426237861456,
                "recall": 0.8903946560196561,
                "f1-score": 0.8873601264763866,
                "support": 26048
            },
            "roc_auc": 0.9477439140272268,
            "score": 0.8903946560196561
        },
        "val": {
            "0": {
                "precision": 0.8964457252641691,
                "recall": 0.9435793731041456,
                "f1-score": 0.919408866995074,
                "support": 4945
            },
            "1": {
                "precision": 0.786697247706422,
                "recall": 0.65625,
                "f1-score": 0.7155771905424201,
                "support": 1568
            },
            "accuracy": 0.8744050360816827,
            "macro avg": {
                "precision": 0.8415714864852956,
                "recall": 0.7999146865520728,
                "f1-score": 0.817493028768747,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8700238593328706,
                "recall": 0.8744050360816827,
                "f1-score": 0.8703365395457017,
                "support": 6513
            },
            "roc_auc": 0.9265758161201793,
            "score": 0.8744050360816827
        },
        "test": {
            "0": {
                "precision": 0.8977962067112033,
                "recall": 0.9402492963409731,
                "f1-score": 0.9185324848770524,
                "support": 12435
            },
            "1": {
                "precision": 0.7719459791282995,
                "recall": 0.6539261570462819,
                "f1-score": 0.7080518018018017,
                "support": 3846
            },
            "accuracy": 0.8726122474049506,
            "macro avg": {
                "precision": 0.8348710929197514,
                "recall": 0.7970877266936275,
                "f1-score": 0.8132921433394271,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8680670761121093,
                "recall": 0.8726122474049506,
                "f1-score": 0.8688114169385097,
                "support": 16281
            },
            "roc_auc": 0.92764622527,
            "score": 0.8726122474049506
        }
    }
}
