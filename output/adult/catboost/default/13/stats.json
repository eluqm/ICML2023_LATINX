{
    "config": {
        "data": {
            "cat_policy": "indices",
            "path": "data/adult"
        },
        "fit": {
            "logging_level": "Verbose"
        },
        "model": {
            "iterations": 2000,
            "task_type": "CPU",
            "thread_count": 10
        },
        "seed": 13
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "dataset": "adult",
    "algorithm": "catboost_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9078713275953263,
                "recall": 0.9547914032869785,
                "f1-score": 0.9307404121068718,
                "support": 19775
            },
            "1": {
                "precision": 0.8297467149114455,
                "recall": 0.694564004463574,
                "f1-score": 0.7561610551891704,
                "support": 6273
            },
            "accuracy": 0.8921222358722358,
            "macro avg": {
                "precision": 0.8688090212533859,
                "recall": 0.8246777038752763,
                "f1-score": 0.843450733648021,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8890569965385854,
                "recall": 0.8921222358722358,
                "f1-score": 0.8886974028184527,
                "support": 26048
            },
            "roc_auc": 0.9483434493302322,
            "score": 0.8921222358722358
        },
        "val": {
            "0": {
                "precision": 0.8939220183486238,
                "recall": 0.9458038422649141,
                "f1-score": 0.9191313746683699,
                "support": 4945
            },
            "1": {
                "precision": 0.7907884465261514,
                "recall": 0.6460459183673469,
                "f1-score": 0.7111267111267112,
                "support": 1568
            },
            "accuracy": 0.873637340703209,
            "macro avg": {
                "precision": 0.8423552324373876,
                "recall": 0.7959248803161305,
                "f1-score": 0.8151290428975406,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8690926861487718,
                "recall": 0.873637340703209,
                "f1-score": 0.8690544036207235,
                "support": 6513
            },
            "roc_auc": 0.9264890840056953,
            "score": 0.873637340703209
        },
        "test": {
            "0": {
                "precision": 0.8967391304347826,
                "recall": 0.9420989143546441,
                "f1-score": 0.9188595631201223,
                "support": 12435
            },
            "1": {
                "precision": 0.776188995958968,
                "recall": 0.6492459698387936,
                "f1-score": 0.7070649865496249,
                "support": 3846
            },
            "accuracy": 0.8729193538480438,
            "macro avg": {
                "precision": 0.8364640631968753,
                "recall": 0.7956724420967188,
                "f1-score": 0.8129622748348736,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8682620210929742,
                "recall": 0.8729193538480438,
                "f1-score": 0.868828119014101,
                "support": 16281
            },
            "roc_auc": 0.9275085148962853,
            "score": 0.8729193538480438
        }
    }
}
