{
    "config": {
        "data": {
            "cat_policy": "indices",
            "path": "data/adult"
        },
        "fit": {
            "logging_level": "Verbose"
        },
        "model": {
            "iterations": 2000,
            "task_type": "CPU",
            "thread_count": 10
        },
        "seed": 4
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "dataset": "adult",
    "algorithm": "catboost_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9035255796129527,
                "recall": 0.9538305941845765,
                "f1-score": 0.9279968512459719,
                "support": 19775
            },
            "1": {
                "precision": 0.8234725444702243,
                "recall": 0.678941495297306,
                "f1-score": 0.744255133245959,
                "support": 6273
            },
            "accuracy": 0.8876305282555282,
            "macro avg": {
                "precision": 0.8634990620415885,
                "recall": 0.8163860447409412,
                "f1-score": 0.8361259922459654,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8842468369282807,
                "recall": 0.8876305282555282,
                "f1-score": 0.8837473197266966,
                "support": 26048
            },
            "roc_auc": 0.9446282474425844,
            "score": 0.8876305282555282
        },
        "val": {
            "0": {
                "precision": 0.8933613124761541,
                "recall": 0.9470171890798786,
                "f1-score": 0.9194070874644155,
                "support": 4945
            },
            "1": {
                "precision": 0.7938630999213218,
                "recall": 0.6434948979591837,
                "f1-score": 0.7108136667840789,
                "support": 1568
            },
            "accuracy": 0.8739444188545985,
            "macro avg": {
                "precision": 0.8436122061987379,
                "recall": 0.7952560435195312,
                "f1-score": 0.8151103771242472,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8694071903686803,
                "recall": 0.8739444188545985,
                "f1-score": 0.8691883735650193,
                "support": 6513
            },
            "roc_auc": 0.9264610330987806,
            "score": 0.8739444188545985
        },
        "test": {
            "0": {
                "precision": 0.8952068386505877,
                "recall": 0.9432247687977483,
                "f1-score": 0.9185887144143792,
                "support": 12435
            },
            "1": {
                "precision": 0.7779175841459578,
                "recall": 0.6430057202288092,
                "f1-score": 0.7040569395017794,
                "support": 3846
            },
            "accuracy": 0.8723051409618574,
            "macro avg": {
                "precision": 0.8365622113982727,
                "recall": 0.7931152445132787,
                "f1-score": 0.8113228269580792,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8675000348409442,
                "recall": 0.8723051409618574,
                "f1-score": 0.8679106721372549,
                "support": 16281
            },
            "roc_auc": 0.9276042388699972,
            "score": 0.8723051409618574
        }
    }
}
