{
    "config": {
        "data": {
            "cat_policy": "indices",
            "path": "data/adult"
        },
        "fit": {
            "logging_level": "Verbose"
        },
        "model": {
            "iterations": 2000,
            "task_type": "CPU",
            "thread_count": 10
        },
        "seed": 7
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "dataset": "adult",
    "algorithm": "catboost_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9118441358024691,
                "recall": 0.9561567635903919,
                "f1-score": 0.9334748586803584,
                "support": 19775
            },
            "1": {
                "precision": 0.8367846385542169,
                "recall": 0.7085923800414474,
                "f1-score": 0.7673716012084592,
                "support": 6273
            },
            "accuracy": 0.8965371621621622,
            "macro avg": {
                "precision": 0.874314387178343,
                "recall": 0.8323745718159197,
                "f1-score": 0.8504232299444088,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8937679600408641,
                "recall": 0.8965371621621622,
                "f1-score": 0.893473102917105,
                "support": 26048
            },
            "roc_auc": 0.9524223676088177,
            "score": 0.8965371621621622
        },
        "val": {
            "0": {
                "precision": 0.894937917860554,
                "recall": 0.9474216380182002,
                "f1-score": 0.9204322200392928,
                "support": 4945
            },
            "1": {
                "precision": 0.7965571205007824,
                "recall": 0.6492346938775511,
                "f1-score": 0.7153900210822207,
                "support": 1568
            },
            "accuracy": 0.8756333486872409,
            "macro avg": {
                "precision": 0.8457475191806683,
                "recall": 0.7983281659478756,
                "f1-score": 0.8179111205607568,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8712528126463484,
                "recall": 0.8756333486872409,
                "f1-score": 0.8710684601798289,
                "support": 6513
            },
            "roc_auc": 0.9262249540867916,
            "score": 0.8756333486872409
        },
        "test": {
            "0": {
                "precision": 0.8965226715686274,
                "recall": 0.9412947326095698,
                "f1-score": 0.9183633439253069,
                "support": 12435
            },
            "1": {
                "precision": 0.7736434108527132,
                "recall": 0.6487259490379615,
                "f1-score": 0.7056993353132512,
                "support": 3846
            },
            "accuracy": 0.8721822983846201,
            "macro avg": {
                "precision": 0.8350830412106702,
                "recall": 0.7950103408237656,
                "f1-score": 0.8120313396192791,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8674953614087229,
                "recall": 0.8721822983846201,
                "f1-score": 0.8681265171258494,
                "support": 16281
            },
            "roc_auc": 0.927131567771758,
            "score": 0.8721822983846201
        }
    }
}
