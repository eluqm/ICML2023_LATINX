{
    "config": {
        "data": {
            "cat_policy": "indices",
            "path": "data/adult"
        },
        "fit": {
            "logging_level": "Verbose"
        },
        "model": {
            "iterations": 2000,
            "task_type": "CPU",
            "thread_count": 10
        },
        "seed": 2
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "dataset": "adult",
    "algorithm": "catboost_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9096849136053434,
                "recall": 0.9504424778761061,
                "f1-score": 0.9296171728163023,
                "support": 19775
            },
            "1": {
                "precision": 0.8180805643215148,
                "recall": 0.7025346724055476,
                "f1-score": 0.755917667238422,
                "support": 6273
            },
            "accuracy": 0.890740171990172,
            "macro avg": {
                "precision": 0.8638827389634292,
                "recall": 0.8264885751408269,
                "f1-score": 0.8427674200273622,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.887624329949882,
                "recall": 0.890740171990172,
                "f1-score": 0.887786053402526,
                "support": 26048
            },
            "roc_auc": 0.9471643144631045,
            "score": 0.890740171990172
        },
        "val": {
            "0": {
                "precision": 0.8978214767688452,
                "recall": 0.9417593528816987,
                "f1-score": 0.9192656928543228,
                "support": 4945
            },
            "1": {
                "precision": 0.7828054298642534,
                "recall": 0.6619897959183674,
                "f1-score": 0.7173462335867312,
                "support": 1568
            },
            "accuracy": 0.8744050360816827,
            "macro avg": {
                "precision": 0.8403134533165493,
                "recall": 0.8018745744000331,
                "f1-score": 0.818305963220527,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.870131447358988,
                "recall": 0.8744050360816827,
                "f1-score": 0.8706537302976541,
                "support": 6513
            },
            "roc_auc": 0.9272768953385198,
            "score": 0.8744050360816827
        },
        "test": {
            "0": {
                "precision": 0.8989673242909988,
                "recall": 0.9380780056292722,
                "f1-score": 0.9181063319035064,
                "support": 12435
            },
            "1": {
                "precision": 0.7670196671709532,
                "recall": 0.6591263650546022,
                "f1-score": 0.7089917494056776,
                "support": 3846
            },
            "accuracy": 0.8721822983846201,
            "macro avg": {
                "precision": 0.8329934957309759,
                "recall": 0.7986021853419372,
                "f1-score": 0.813549040654592,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8677978206190071,
                "recall": 0.8721822983846201,
                "f1-score": 0.8687079728170468,
                "support": 16281
            },
            "roc_auc": 0.927525148452661,
            "score": 0.8721822983846201
        }
    }
}
