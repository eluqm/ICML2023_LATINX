{
    "config": {
        "data": {
            "cat_policy": "indices",
            "path": "data/adult"
        },
        "fit": {
            "logging_level": "Verbose"
        },
        "model": {
            "iterations": 2000,
            "task_type": "CPU",
            "thread_count": 10
        },
        "seed": 11
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "dataset": "adult",
    "algorithm": "catboost_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.912081541954495,
                "recall": 0.9547914032869785,
                "f1-score": 0.9329479197549165,
                "support": 19775
            },
            "1": {
                "precision": 0.8328034411819712,
                "recall": 0.7098676869121633,
                "f1-score": 0.7664371772805509,
                "support": 6273
            },
            "accuracy": 0.8958077395577395,
            "macro avg": {
                "precision": 0.8724424915682332,
                "recall": 0.8323295450995709,
                "f1-score": 0.8496925485177338,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8929894225539252,
                "recall": 0.8958077395577395,
                "f1-score": 0.892848031566123,
                "support": 26048
            },
            "roc_auc": 0.9529638208258338,
            "score": 0.8958077395577395
        },
        "val": {
            "0": {
                "precision": 0.8947972456006121,
                "recall": 0.9460060667340748,
                "f1-score": 0.9196893738326944,
                "support": 4945
            },
            "1": {
                "precision": 0.7922178988326848,
                "recall": 0.6492346938775511,
                "f1-score": 0.7136347704171048,
                "support": 1568
            },
            "accuracy": 0.8745585751573776,
            "macro avg": {
                "precision": 0.8435075722166485,
                "recall": 0.797620380305813,
                "f1-score": 0.8166620721248996,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8701013426784395,
                "recall": 0.8745585751573776,
                "f1-score": 0.8700818783381996,
                "support": 6513
            },
            "roc_auc": 0.9265755581808052,
            "score": 0.8745585751573776
        },
        "test": {
            "0": {
                "precision": 0.8985696708705014,
                "recall": 0.9396863691194209,
                "f1-score": 0.9186681866425568,
                "support": 12435
            },
            "1": {
                "precision": 0.77113213304852,
                "recall": 0.657046281851274,
                "f1-score": 0.7095325003509757,
                "support": 3846
            },
            "accuracy": 0.8729193538480438,
            "macro avg": {
                "precision": 0.8348509019595107,
                "recall": 0.7983663254853475,
                "f1-score": 0.8141003434967662,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8684655758847303,
                "recall": 0.8729193538480438,
                "f1-score": 0.8692648422854891,
                "support": 16281
            },
            "roc_auc": 0.9270629112257374,
            "score": 0.8729193538480438
        }
    }
}
