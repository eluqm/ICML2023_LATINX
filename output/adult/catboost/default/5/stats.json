{
    "config": {
        "data": {
            "cat_policy": "indices",
            "path": "data/adult"
        },
        "fit": {
            "logging_level": "Verbose"
        },
        "model": {
            "iterations": 2000,
            "task_type": "CPU",
            "thread_count": 10
        },
        "seed": 5
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "dataset": "adult",
    "algorithm": "catboost_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9065384615384615,
                "recall": 0.9535271807838179,
                "f1-score": 0.9294393099199013,
                "support": 19775
            },
            "1": {
                "precision": 0.8248856707317073,
                "recall": 0.6901004304160688,
                "f1-score": 0.7514972658623383,
                "support": 6273
            },
            "accuracy": 0.8900875307125307,
            "macro avg": {
                "precision": 0.8657120661350843,
                "recall": 0.8218138055999433,
                "f1-score": 0.8404682878911198,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8868744582855912,
                "recall": 0.8900875307125307,
                "f1-score": 0.8865864827403447,
                "support": 26048
            },
            "roc_auc": 0.9455378709509561,
            "score": 0.8900875307125307
        },
        "val": {
            "0": {
                "precision": 0.8948173646968828,
                "recall": 0.9462082912032356,
                "f1-score": 0.9197955573029291,
                "support": 4945
            },
            "1": {
                "precision": 0.7928348909657321,
                "recall": 0.6492346938775511,
                "f1-score": 0.7138849929873773,
                "support": 1568
            },
            "accuracy": 0.8747121142330723,
            "macro avg": {
                "precision": 0.8438261278313075,
                "recall": 0.7977214925403933,
                "f1-score": 0.8168402751451531,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8702651585230083,
                "recall": 0.8747121142330723,
                "f1-score": 0.8702227391167191,
                "support": 6513
            },
            "roc_auc": 0.9271315465013104,
            "score": 0.8747121142330723
        },
        "test": {
            "0": {
                "precision": 0.8981467299739623,
                "recall": 0.9431443506232409,
                "f1-score": 0.9200957125485427,
                "support": 12435
            },
            "1": {
                "precision": 0.7806391560657773,
                "recall": 0.6541861674466979,
                "f1-score": 0.7118404300466827,
                "support": 3846
            },
            "accuracy": 0.8748848350838401,
            "macro avg": {
                "precision": 0.8393929430198698,
                "recall": 0.7986652590349694,
                "f1-score": 0.8159680712976127,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8703883533846324,
                "recall": 0.8748848350838401,
                "f1-score": 0.8709003427001212,
                "support": 16281
            },
            "roc_auc": 0.9279261938471105,
            "score": 0.8748848350838401
        }
    }
}
