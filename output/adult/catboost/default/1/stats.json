{
    "config": {
        "data": {
            "cat_policy": "indices",
            "path": "data/adult"
        },
        "fit": {
            "logging_level": "Verbose"
        },
        "model": {
            "iterations": 2000,
            "task_type": "CPU",
            "thread_count": 10
        },
        "seed": 1
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "dataset": "adult",
    "algorithm": "catboost_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9082741631647587,
                "recall": 0.950897597977244,
                "f1-score": 0.9290972874153862,
                "support": 19775
            },
            "1": {
                "precision": 0.8183348924228251,
                "recall": 0.697274031563845,
                "f1-score": 0.7529695300395937,
                "support": 6273
            },
            "accuracy": 0.8898187960687961,
            "macro avg": {
                "precision": 0.8633045277937919,
                "recall": 0.8240858147705445,
                "f1-score": 0.84103340872749,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.886614571435484,
                "recall": 0.8898187960687961,
                "f1-score": 0.8866813851573109,
                "support": 26048
            },
            "roc_auc": 0.9467667524596713,
            "score": 0.8898187960687961
        },
        "val": {
            "0": {
                "precision": 0.8956937799043062,
                "recall": 0.9464105156723963,
                "f1-score": 0.9203539823008848,
                "support": 4945
            },
            "1": {
                "precision": 0.7942546583850931,
                "recall": 0.6524234693877551,
                "f1-score": 0.7163865546218487,
                "support": 1568
            },
            "accuracy": 0.8756333486872409,
            "macro avg": {
                "precision": 0.8449742191446996,
                "recall": 0.7994169925300757,
                "f1-score": 0.8183702684613667,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8712723853791833,
                "recall": 0.8756333486872409,
                "f1-score": 0.8712489728427659,
                "support": 6513
            },
            "roc_auc": 0.9269352546377498,
            "score": 0.8756333486872409
        },
        "test": {
            "0": {
                "precision": 0.8983649343670838,
                "recall": 0.9411338962605549,
                "f1-score": 0.9192522189930092,
                "support": 12435
            },
            "1": {
                "precision": 0.7750460971112477,
                "recall": 0.655746229849194,
                "f1-score": 0.7104225352112676,
                "support": 3846
            },
            "accuracy": 0.873717830600086,
            "macro avg": {
                "precision": 0.8367055157391657,
                "recall": 0.7984400630548745,
                "f1-score": 0.8148373771021384,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8692337846781245,
                "recall": 0.873717830600086,
                "f1-score": 0.8699211604692958,
                "support": 16281
            },
            "roc_auc": 0.9278921635353552,
            "score": 0.873717830600086
        }
    }
}
