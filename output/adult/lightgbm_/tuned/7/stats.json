{
    "config": {
        "data": {
            "cat_policy": "indices",
            "path": "data/adult",
            "y_policy": "mean_std"
        },
        "fit": {
            "early_stopping_rounds": 50,
            "verbose": true
        },
        "model": {
            "colsample_bytree": 0.7520316396425557,
            "learning_rate": 0.03012327705724217,
            "min_child_samples": 8,
            "min_child_weight": 0.00794616343686661,
            "n_estimators": 2000,
            "n_jobs": 1,
            "num_leaves": 40,
            "reg_lambda": 0.003343640211399975,
            "subsample": 0.9425389542354896
        },
        "seed": 7
    },
    "environment": {},
    "dataset": "adult",
    "algorithm": "lightgbm_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9072189805661378,
                "recall": 0.9513527180783818,
                "f1-score": 0.9287618483412323,
                "support": 19775
            },
            "1": {
                "precision": 0.8188665034833364,
                "recall": 0.6932886975928583,
                "f1-score": 0.7508632596685083,
                "support": 6273
            },
            "accuracy": 0.8892045454545454,
            "macro avg": {
                "precision": 0.8630427420247371,
                "recall": 0.8223207078356201,
                "f1-score": 0.8398125540048703,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8859415278350101,
                "recall": 0.8892045454545454,
                "f1-score": 0.885919486288714,
                "support": 26048
            },
            "roc_auc": 0.948038274522702,
            "score": 0.8892045454545454
        },
        "val": {
            "0": {
                "precision": 0.894122152019912,
                "recall": 0.9443882709807887,
                "f1-score": 0.9185680566483085,
                "support": 4945
            },
            "1": {
                "precision": 0.7868217054263565,
                "recall": 0.6473214285714286,
                "f1-score": 0.7102869139258223,
                "support": 1568
            },
            "accuracy": 0.8728696453247351,
            "macro avg": {
                "precision": 0.8404719287231343,
                "recall": 0.7958548497761087,
                "f1-score": 0.8144274852870654,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8682896477578675,
                "recall": 0.8728696453247351,
                "f1-score": 0.8684245234395171,
                "support": 6513
            },
            "roc_auc": 0.9273999969047275,
            "score": 0.8728696453247351
        },
        "test": {
            "0": {
                "precision": 0.8969111673181575,
                "recall": 0.9410534780860474,
                "f1-score": 0.9184522407974256,
                "support": 12435
            },
            "1": {
                "precision": 0.7733457019171305,
                "recall": 0.6502860114404576,
                "f1-score": 0.706497175141243,
                "support": 3846
            },
            "accuracy": 0.872366562250476,
            "macro avg": {
                "precision": 0.835128434617644,
                "recall": 0.7956697447632526,
                "f1-score": 0.8124747079693343,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8677217575808963,
                "recall": 0.872366562250476,
                "f1-score": 0.8683828849523498,
                "support": 16281
            },
            "roc_auc": 0.9273446989347205,
            "score": 0.872366562250476
        }
    },
    "time": "0:00:02"
}
