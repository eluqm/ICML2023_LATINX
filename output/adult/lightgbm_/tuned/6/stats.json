{
    "config": {
        "data": {
            "cat_policy": "indices",
            "path": "data/adult",
            "y_policy": "mean_std"
        },
        "fit": {
            "early_stopping_rounds": 50,
            "verbose": true
        },
        "model": {
            "colsample_bytree": 0.7520316396425557,
            "learning_rate": 0.03012327705724217,
            "min_child_samples": 8,
            "min_child_weight": 0.00794616343686661,
            "n_estimators": 2000,
            "n_jobs": 1,
            "num_leaves": 40,
            "reg_lambda": 0.003343640211399975,
            "subsample": 0.9425389542354896
        },
        "seed": 6
    },
    "environment": {},
    "dataset": "adult",
    "algorithm": "lightgbm_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.905105625330831,
                "recall": 0.9511504424778761,
                "f1-score": 0.9275569582799091,
                "support": 19775
            },
            "1": {
                "precision": 0.8165938864628821,
                "recall": 0.6856368563685636,
                "f1-score": 0.7454072790294628,
                "support": 6273
            },
            "accuracy": 0.887208230958231,
            "macro avg": {
                "precision": 0.8608497558968566,
                "recall": 0.8183936494232198,
                "f1-score": 0.836482118654686,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8837898184389912,
                "recall": 0.887208230958231,
                "f1-score": 0.8836908289057518,
                "support": 26048
            },
            "roc_auc": 0.9447008520654107,
            "score": 0.887208230958231
        },
        "val": {
            "0": {
                "precision": 0.8945155742403975,
                "recall": 0.9466127401415572,
                "f1-score": 0.9198270780113972,
                "support": 4945
            },
            "1": {
                "precision": 0.79375,
                "recall": 0.6479591836734694,
                "f1-score": 0.7134831460674158,
                "support": 1568
            },
            "accuracy": 0.8747121142330723,
            "macro avg": {
                "precision": 0.8441327871201987,
                "recall": 0.7972859619075132,
                "f1-score": 0.8166551120394065,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8702563357314242,
                "recall": 0.8747121142330723,
                "f1-score": 0.8701499268847025,
                "support": 6513
            },
            "roc_auc": 0.9269356415468109,
            "score": 0.8747121142330723
        },
        "test": {
            "0": {
                "precision": 0.895513261484369,
                "recall": 0.9421793325291515,
                "f1-score": 0.9182537816443294,
                "support": 12435
            },
            "1": {
                "precision": 0.7751719824890556,
                "recall": 0.6445657826313053,
                "f1-score": 0.7038614423622942,
                "support": 3846
            },
            "accuracy": 0.871875191941527,
            "macro avg": {
                "precision": 0.8353426219867124,
                "recall": 0.7933725575802284,
                "f1-score": 0.8110576120033117,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8670854892949472,
                "recall": 0.871875191941527,
                "f1-score": 0.867608677726959,
                "support": 16281
            },
            "roc_auc": 0.9271181229235499,
            "score": 0.871875191941527
        }
    },
    "time": "0:00:02"
}
