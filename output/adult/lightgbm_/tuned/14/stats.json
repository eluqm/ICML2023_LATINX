{
    "config": {
        "data": {
            "cat_policy": "indices",
            "path": "data/adult",
            "y_policy": "mean_std"
        },
        "fit": {
            "early_stopping_rounds": 50,
            "verbose": true
        },
        "model": {
            "colsample_bytree": 0.7520316396425557,
            "learning_rate": 0.03012327705724217,
            "min_child_samples": 8,
            "min_child_weight": 0.00794616343686661,
            "n_estimators": 2000,
            "n_jobs": 1,
            "num_leaves": 40,
            "reg_lambda": 0.003343640211399975,
            "subsample": 0.9425389542354896
        },
        "seed": 14
    },
    "environment": {},
    "dataset": "adult",
    "algorithm": "lightgbm_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9066281031573873,
                "recall": 0.9510998735777497,
                "f1-score": 0.9283316880552814,
                "support": 19775
            },
            "1": {
                "precision": 0.8176503865736375,
                "recall": 0.6912163239279452,
                "f1-score": 0.7491361437456808,
                "support": 6273
            },
            "accuracy": 0.8885135135135135,
            "macro avg": {
                "precision": 0.8621392448655124,
                "recall": 0.8211580987528475,
                "f1-score": 0.8387339159004812,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.885200077353876,
                "recall": 0.8885135135135135,
                "f1-score": 0.8851769871395057,
                "support": 26048
            },
            "roc_auc": 0.9467745679464677,
            "score": 0.8885135135135135
        },
        "val": {
            "0": {
                "precision": 0.8950794562511967,
                "recall": 0.9453993933265925,
                "f1-score": 0.9195515342250197,
                "support": 4945
            },
            "1": {
                "precision": 0.7906976744186046,
                "recall": 0.6505102040816326,
                "f1-score": 0.7137858642407277,
                "support": 1568
            },
            "accuracy": 0.8744050360816827,
            "macro avg": {
                "precision": 0.8428885653349006,
                "recall": 0.7979547987041126,
                "f1-score": 0.8166686992328737,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8699496184017411,
                "recall": 0.8744050360816827,
                "f1-score": 0.8700135992433876,
                "support": 6513
            },
            "roc_auc": 0.9275555988320505,
            "score": 0.8744050360816827
        },
        "test": {
            "0": {
                "precision": 0.896541169268442,
                "recall": 0.9421793325291515,
                "f1-score": 0.9187938673881503,
                "support": 12435
            },
            "1": {
                "precision": 0.7762215997510116,
                "recall": 0.6484659386375455,
                "f1-score": 0.7066156679416348,
                "support": 3846
            },
            "accuracy": 0.8727965112708065,
            "macro avg": {
                "precision": 0.8363813845097268,
                "recall": 0.7953226355833485,
                "f1-score": 0.8127047676648925,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.868118525428135,
                "recall": 0.8727965112708065,
                "f1-score": 0.8686718014787284,
                "support": 16281
            },
            "roc_auc": 0.9273845839237671,
            "score": 0.8727965112708065
        }
    },
    "time": "0:00:02"
}
