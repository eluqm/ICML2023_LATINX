{
    "config": {
        "data": {
            "cat_policy": "indices",
            "path": "data/adult",
            "y_policy": "mean_std"
        },
        "fit": {
            "early_stopping_rounds": 50,
            "verbose": true
        },
        "model": {
            "colsample_bytree": 0.7520316396425557,
            "learning_rate": 0.03012327705724217,
            "min_child_samples": 8,
            "min_child_weight": 0.00794616343686661,
            "n_estimators": 2000,
            "n_jobs": 1,
            "num_leaves": 40,
            "reg_lambda": 0.003343640211399975,
            "subsample": 0.9425389542354896
        },
        "seed": 4
    },
    "environment": {},
    "dataset": "adult",
    "algorithm": "lightgbm_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9061263868789194,
                "recall": 0.9498862199747156,
                "f1-score": 0.9274904332798419,
                "support": 19775
            },
            "1": {
                "precision": 0.8136517487777359,
                "recall": 0.6897816036983899,
                "f1-score": 0.7466137520490035,
                "support": 6273
            },
            "accuracy": 0.8872466216216216,
            "macro avg": {
                "precision": 0.8598890678283277,
                "recall": 0.8198339118365527,
                "f1-score": 0.8370520926644227,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8838562162397638,
                "recall": 0.8872466216216216,
                "f1-score": 0.8839308731845927,
                "support": 26048
            },
            "roc_auc": 0.9459702096537586,
            "score": 0.8872466216216216
        },
        "val": {
            "0": {
                "precision": 0.8947368421052632,
                "recall": 0.9453993933265925,
                "f1-score": 0.9193706981317601,
                "support": 4945
            },
            "1": {
                "precision": 0.7903726708074534,
                "recall": 0.6492346938775511,
                "f1-score": 0.7128851540616247,
                "support": 1568
            },
            "accuracy": 0.8740979579302932,
            "macro avg": {
                "precision": 0.8425547564563582,
                "recall": 0.7973170436020718,
                "f1-score": 0.8161279260966924,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.869611243979213,
                "recall": 0.8740979579302932,
                "f1-score": 0.869659453988973,
                "support": 6513
            },
            "roc_auc": 0.9270645467489321,
            "score": 0.8740979579302932
        },
        "test": {
            "0": {
                "precision": 0.8969878132904116,
                "recall": 0.9411338962605549,
                "f1-score": 0.918530727572404,
                "support": 12435
            },
            "1": {
                "precision": 0.7736549165120594,
                "recall": 0.6505460218408736,
                "f1-score": 0.7067796610169491,
                "support": 3846
            },
            "accuracy": 0.8724894048277133,
            "macro avg": {
                "precision": 0.8353213649012354,
                "recall": 0.7958399590507143,
                "f1-score": 0.8126551942946765,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8678533423728055,
                "recall": 0.8724894048277133,
                "f1-score": 0.868509561675206,
                "support": 16281
            },
            "roc_auc": 0.9273076576460727,
            "score": 0.8724894048277133
        }
    },
    "time": "0:00:02"
}
