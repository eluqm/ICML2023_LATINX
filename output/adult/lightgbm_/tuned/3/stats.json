{
    "config": {
        "data": {
            "cat_policy": "indices",
            "path": "data/adult",
            "y_policy": "mean_std"
        },
        "fit": {
            "early_stopping_rounds": 50,
            "verbose": true
        },
        "model": {
            "colsample_bytree": 0.7520316396425557,
            "learning_rate": 0.03012327705724217,
            "min_child_samples": 8,
            "min_child_weight": 0.00794616343686661,
            "n_estimators": 2000,
            "n_jobs": 1,
            "num_leaves": 40,
            "reg_lambda": 0.003343640211399975,
            "subsample": 0.9425389542354896
        },
        "seed": 3
    },
    "environment": {},
    "dataset": "adult",
    "algorithm": "lightgbm_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9023371886547967,
                "recall": 0.9507964601769912,
                "f1-score": 0.9259332217078695,
                "support": 19775
            },
            "1": {
                "precision": 0.8132796008443677,
                "recall": 0.675593814761677,
                "f1-score": 0.7380703587600139,
                "support": 6273
            },
            "accuracy": 0.8845208845208845,
            "macro avg": {
                "precision": 0.8578083947495823,
                "recall": 0.813195137469334,
                "f1-score": 0.8320017902339417,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8808899278925569,
                "recall": 0.8845208845208845,
                "f1-score": 0.8806912169753796,
                "support": 26048
            },
            "roc_auc": 0.9420848647394781,
            "score": 0.8845208845208845
        },
        "val": {
            "0": {
                "precision": 0.8926123381568926,
                "recall": 0.9480283114256826,
                "f1-score": 0.9194861233696185,
                "support": 4945
            },
            "1": {
                "precision": 0.796193497224425,
                "recall": 0.6403061224489796,
                "f1-score": 0.7097914457405443,
                "support": 1568
            },
            "accuracy": 0.8739444188545985,
            "macro avg": {
                "precision": 0.8444029176906588,
                "recall": 0.794167216937331,
                "f1-score": 0.8146387845550814,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8693995725216846,
                "recall": 0.8739444188545985,
                "f1-score": 0.8690022826629722,
                "support": 6513
            },
            "roc_auc": 0.9261540852438043,
            "score": 0.8739444188545985
        },
        "test": {
            "0": {
                "precision": 0.8948090555682597,
                "recall": 0.9440289505428227,
                "f1-score": 0.9187602723644048,
                "support": 12435
            },
            "1": {
                "precision": 0.7798861480075902,
                "recall": 0.641185647425897,
                "f1-score": 0.7037671232876713,
                "support": 3846
            },
            "accuracy": 0.8724894048277133,
            "macro avg": {
                "precision": 0.8373476017879249,
                "recall": 0.7926072989843598,
                "f1-score": 0.8112636978260381,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8676612450849764,
                "recall": 0.8724894048277133,
                "f1-score": 0.8679732413866322,
                "support": 16281
            },
            "roc_auc": 0.9264902296936268,
            "score": 0.8724894048277133
        }
    },
    "time": "0:00:01"
}
