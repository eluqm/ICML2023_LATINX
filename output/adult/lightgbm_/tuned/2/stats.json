{
    "config": {
        "data": {
            "cat_policy": "indices",
            "path": "data/adult",
            "y_policy": "mean_std"
        },
        "fit": {
            "early_stopping_rounds": 50,
            "verbose": true
        },
        "model": {
            "colsample_bytree": 0.7520316396425557,
            "learning_rate": 0.03012327705724217,
            "min_child_samples": 8,
            "min_child_weight": 0.00794616343686661,
            "n_estimators": 2000,
            "n_jobs": 1,
            "num_leaves": 40,
            "reg_lambda": 0.003343640211399975,
            "subsample": 0.9425389542354896
        },
        "seed": 2
    },
    "environment": {},
    "dataset": "adult",
    "algorithm": "lightgbm_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9067155184881647,
                "recall": 0.9510998735777497,
                "f1-score": 0.928377511229577,
                "support": 19775
            },
            "1": {
                "precision": 0.8177191328934967,
                "recall": 0.6915351506456241,
                "f1-score": 0.7493522197270684,
                "support": 6273
            },
            "accuracy": 0.8885902948402948,
            "macro avg": {
                "precision": 0.8622173256908308,
                "recall": 0.8213175121116869,
                "f1-score": 0.8388648654783227,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8852829967269795,
                "recall": 0.8885902948402948,
                "f1-score": 0.8852638113833227,
                "support": 26048
            },
            "roc_auc": 0.9473274158933305,
            "score": 0.8885902948402948
        },
        "val": {
            "0": {
                "precision": 0.8948275862068965,
                "recall": 0.9445904954499494,
                "f1-score": 0.9190359075258239,
                "support": 4945
            },
            "1": {
                "precision": 0.7880897138437741,
                "recall": 0.6498724489795918,
                "f1-score": 0.7123383432366305,
                "support": 1568
            },
            "accuracy": 0.873637340703209,
            "macro avg": {
                "precision": 0.8414586500253354,
                "recall": 0.7972314722147706,
                "f1-score": 0.8156871253812272,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8691305212805376,
                "recall": 0.873637340703209,
                "f1-score": 0.8692736196699272,
                "support": 6513
            },
            "roc_auc": 0.927475315201915,
            "score": 0.873637340703209
        },
        "test": {
            "0": {
                "precision": 0.8968661405256302,
                "recall": 0.9412947326095698,
                "f1-score": 0.918543514086165,
                "support": 12435
            },
            "1": {
                "precision": 0.7739938080495357,
                "recall": 0.6500260010400416,
                "f1-score": 0.7066139061616733,
                "support": 3846
            },
            "accuracy": 0.8724894048277133,
            "macro avg": {
                "precision": 0.8354299742875829,
                "recall": 0.7956603668248057,
                "f1-score": 0.8125787101239191,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8678404669980176,
                "recall": 0.8724894048277133,
                "f1-score": 0.8684801720262426,
                "support": 16281
            },
            "roc_auc": 0.9278414160289773,
            "score": 0.8724894048277133
        }
    },
    "time": "0:00:02"
}
