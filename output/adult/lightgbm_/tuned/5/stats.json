{
    "config": {
        "data": {
            "cat_policy": "indices",
            "path": "data/adult",
            "y_policy": "mean_std"
        },
        "fit": {
            "early_stopping_rounds": 50,
            "verbose": true
        },
        "model": {
            "colsample_bytree": 0.7520316396425557,
            "learning_rate": 0.03012327705724217,
            "min_child_samples": 8,
            "min_child_weight": 0.00794616343686661,
            "n_estimators": 2000,
            "n_jobs": 1,
            "num_leaves": 40,
            "reg_lambda": 0.003343640211399975,
            "subsample": 0.9425389542354896
        },
        "seed": 5
    },
    "environment": {},
    "dataset": "adult",
    "algorithm": "lightgbm_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9097235646626716,
                "recall": 0.9519089759797724,
                "f1-score": 0.9303383003434897,
                "support": 19775
            },
            "1": {
                "precision": 0.8224421209858103,
                "recall": 0.7022158456878687,
                "f1-score": 0.7575887866540545,
                "support": 6273
            },
            "accuracy": 0.8917767199017199,
            "macro avg": {
                "precision": 0.8660828428242409,
                "recall": 0.8270624108338205,
                "f1-score": 0.8439635434987721,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8887040431567996,
                "recall": 0.8917767199017199,
                "f1-score": 0.8887359623761285,
                "support": 26048
            },
            "roc_auc": 0.9511844049800654,
            "score": 0.8917767199017199
        },
        "val": {
            "0": {
                "precision": 0.8949684331356419,
                "recall": 0.9460060667340748,
                "f1-score": 0.919779787652379,
                "support": 4945
            },
            "1": {
                "precision": 0.7923794712286159,
                "recall": 0.6498724489795918,
                "f1-score": 0.7140854940434479,
                "support": 1568
            },
            "accuracy": 0.8747121142330723,
            "macro avg": {
                "precision": 0.8436739521821288,
                "recall": 0.7979392578568334,
                "f1-score": 0.8169326408479134,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8702702153757437,
                "recall": 0.8747121142330723,
                "f1-score": 0.8702590364810595,
                "support": 6513
            },
            "roc_auc": 0.9285442804523225,
            "score": 0.8747121142330723
        },
        "test": {
            "0": {
                "precision": 0.896498889144258,
                "recall": 0.9410534780860474,
                "f1-score": 0.9182360326428124,
                "support": 12435
            },
            "1": {
                "precision": 0.7729244114002478,
                "recall": 0.6487259490379615,
                "f1-score": 0.7054000565450947,
                "support": 3846
            },
            "accuracy": 0.8719980345187642,
            "macro avg": {
                "precision": 0.8347116502722529,
                "recall": 0.7948897135620046,
                "f1-score": 0.8118180445939536,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8673073504547756,
                "recall": 0.8719980345187642,
                "f1-score": 0.8679585826046192,
                "support": 16281
            },
            "roc_auc": 0.9284049496278203,
            "score": 0.8719980345187642
        }
    },
    "time": "0:00:02"
}
