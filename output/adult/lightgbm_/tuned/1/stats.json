{
    "config": {
        "data": {
            "cat_policy": "indices",
            "path": "data/adult",
            "y_policy": "mean_std"
        },
        "fit": {
            "early_stopping_rounds": 50,
            "verbose": true
        },
        "model": {
            "colsample_bytree": 0.7520316396425557,
            "learning_rate": 0.03012327705724217,
            "min_child_samples": 8,
            "min_child_weight": 0.00794616343686661,
            "n_estimators": 2000,
            "n_jobs": 1,
            "num_leaves": 40,
            "reg_lambda": 0.003343640211399975,
            "subsample": 0.9425389542354896
        },
        "seed": 1
    },
    "environment": {},
    "dataset": "adult",
    "algorithm": "lightgbm_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9059656218402427,
                "recall": 0.9515044247787611,
                "f1-score": 0.9281767955801105,
                "support": 19775
            },
            "1": {
                "precision": 0.818336806213298,
                "recall": 0.6886657101865137,
                "f1-score": 0.7479224376731302,
                "support": 6273
            },
            "accuracy": 0.8882063882063882,
            "macro avg": {
                "precision": 0.8621512140267703,
                "recall": 0.8200850674826374,
                "f1-score": 0.8380496166266203,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8848624446125161,
                "recall": 0.8882063882063882,
                "f1-score": 0.884767106269972,
                "support": 26048
            },
            "roc_auc": 0.9463388313811748,
            "score": 0.8882063882063882
        },
        "val": {
            "0": {
                "precision": 0.8938611589213998,
                "recall": 0.9451971688574318,
                "f1-score": 0.918812659720857,
                "support": 4945
            },
            "1": {
                "precision": 0.7889408099688473,
                "recall": 0.6460459183673469,
                "f1-score": 0.7103786816269284,
                "support": 1568
            },
            "accuracy": 0.8731767234761246,
            "macro avg": {
                "precision": 0.8414009844451236,
                "recall": 0.7956215436123893,
                "f1-score": 0.8145956706738927,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8686016614305965,
                "recall": 0.8731767234761246,
                "f1-score": 0.8686323315078552,
                "support": 6513
            },
            "roc_auc": 0.927176814861435,
            "score": 0.8731767234761246
        },
        "test": {
            "0": {
                "precision": 0.8958190017580066,
                "recall": 0.9425010052271814,
                "f1-score": 0.9185672858374481,
                "support": 12435
            },
            "1": {
                "precision": 0.7764227642276422,
                "recall": 0.6456058242329693,
                "f1-score": 0.7049971607041454,
                "support": 3846
            },
            "accuracy": 0.872366562250476,
            "macro avg": {
                "precision": 0.8361208829928244,
                "recall": 0.7940534147300753,
                "f1-score": 0.8117822232707967,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8676144731945412,
                "recall": 0.872366562250476,
                "f1-score": 0.8681164105065297,
                "support": 16281
            },
            "roc_auc": 0.9272584783568263,
            "score": 0.872366562250476
        }
    },
    "time": "0:00:02"
}
