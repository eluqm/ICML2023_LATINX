{
    "config": {
        "data": {
            "cat_policy": "indices",
            "path": "data/adult",
            "y_policy": "mean_std"
        },
        "fit": {
            "early_stopping_rounds": 50,
            "verbose": true
        },
        "model": {
            "colsample_bytree": 0.7520316396425557,
            "learning_rate": 0.03012327705724217,
            "min_child_samples": 8,
            "min_child_weight": 0.00794616343686661,
            "n_estimators": 2000,
            "n_jobs": 1,
            "num_leaves": 40,
            "reg_lambda": 0.003343640211399975,
            "subsample": 0.9425389542354896
        },
        "seed": 9
    },
    "environment": {},
    "dataset": "adult",
    "algorithm": "lightgbm_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9079061685490878,
                "recall": 0.9512010113780025,
                "f1-score": 0.9290494653396884,
                "support": 19775
            },
            "1": {
                "precision": 0.8189493433395872,
                "recall": 0.6958393113342898,
                "f1-score": 0.7523916228561578,
                "support": 6273
            },
            "accuracy": 0.8897036240786241,
            "macro avg": {
                "precision": 0.8634277559443375,
                "recall": 0.8235201613561461,
                "f1-score": 0.8407205440979231,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8864831739030805,
                "recall": 0.8897036240786241,
                "f1-score": 0.8865059055309051,
                "support": 26048
            },
            "roc_auc": 0.9488719197298316,
            "score": 0.8897036240786241
        },
        "val": {
            "0": {
                "precision": 0.8954223328864203,
                "recall": 0.9453993933265925,
                "f1-score": 0.9197324414715718,
                "support": 4945
            },
            "1": {
                "precision": 0.7910216718266254,
                "recall": 0.6517857142857143,
                "f1-score": 0.7146853146853147,
                "support": 1568
            },
            "accuracy": 0.8747121142330723,
            "macro avg": {
                "precision": 0.8432220023565229,
                "recall": 0.7985925538061533,
                "f1-score": 0.8172088780784432,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8702879498767844,
                "recall": 0.8747121142330723,
                "f1-score": 0.8703674952408255,
                "support": 6513
            },
            "roc_auc": 0.9281939987825262,
            "score": 0.8747121142330723
        },
        "test": {
            "0": {
                "precision": 0.8971231300345225,
                "recall": 0.940410132689988,
                "f1-score": 0.9182567726737338,
                "support": 12435
            },
            "1": {
                "precision": 0.7717190388170055,
                "recall": 0.6513260530421217,
                "f1-score": 0.706429780033841,
                "support": 3846
            },
            "accuracy": 0.8721208770960015,
            "macro avg": {
                "precision": 0.834421084425764,
                "recall": 0.7958680928660549,
                "f1-score": 0.8123432763537874,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8674993885676243,
                "recall": 0.8721208770960015,
                "f1-score": 0.8682176710403559,
                "support": 16281
            },
            "roc_auc": 0.9278887134576657,
            "score": 0.8721208770960015
        }
    },
    "time": "0:00:02"
}
